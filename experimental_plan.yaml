## load data from external_path
name: Graph Classification/Regression
version: 3.0.0

external_path:
    - load_train_data_path: ./solution/sample_data/train
    - load_inference_data_path: ./solution/sample_data/test
    - save_train_artifacts_path:
    - save_inference_artifacts_path:
    - load_model_path: 

external_path_permission:
    - aws_key_profile:
 
## Parameter setting for experiment 
## 
user_parameters:
    - train_pipeline:
        - step: input
          args:
            - file_type: csv               # (str) csv (default) | parquet
              encoding: utf-8              # (str) utf-8 (default) | euc-kr | utf-16 | ascii | cp949
              # NOTE - AI advisor supports only csv and utf-8 for now.
          ui_args:
            - file_type
            - encoding

        - step: readiness
          args:
            - drop_columns:                # (list of str) none (default) | list of column names
              y_column: target             # (str) a column name
          ui_args:
            - drop_columns
            - y_column

        - step: graph
          args:       
            - dimension: 4                # (int), 64(default), dimension > 1 & even
              num_epochs: 1                 # (int), 10(default)
              num_partitions:               # (int), 1(default)
              use_gpu:                      # (bool), False(default) | True
        
          ui_args:
            - dimension
            - num_epochs
        - step: train
          args:
            - task:                         # (str), classification(default) | regression
              epochs: 1                     # (int), 10(default)
        ui_args:
            - task
            - epochs
        - step: output
          args:

                                                      
    - inference_pipeline:
        - step: input
          args:
            - file_type: csv               # (str) csv (default) | parquet
              encoding: utf-8              # (str) utf-8 (default) | euc-kr | utf-16 | ascii | cp949
              # NOTE - AI advisor supports only csv and utf-8 for now.
          ui_args:
            - file_type
            - encoding 

        - step: readiness
          args:
            - drop_columns:                # (list of str) none (default) | list of column names
              y_column:                    # (str) a column name
          ui_args:
            - drop_columns

        - step: inference
          args:
        
        - step: output
          args:

   
## asset information       
asset_source:
    - train_pipeline:
        - step: input
          source:  ## git | local 
            code: http://mod.lge.com/hub/dxadvtech/assets/input.git
            branch: v1.0.0_tabular
            requirements:
              - pandas==1.5.3
              - torch==2.0.0
        
        - step: readiness
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/readiness.git
            branch: v3.0.0_gcr
            requirements:
              - pandas==1.5.3        

        - step: graph
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/gfe.git
            branch: feature/dnn
            requirements:
              - torch==2.0.0
              - requirements.txt

        - step: train
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/gdnn.git
            branch: main
            requirements:
              - pandas==1.5.3
              - torch==2.0.0
              - requirements.txt
        
        - step: output
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/output.git
            branch: output_dev
            requirements:
              - requirements.txt


   
    - inference_pipeline:
        - step: input
          source:  ## git | local
            code: local
            branch: v1.0.0_tabular
            requirements:
              - pandas==1.5.3

        - step: readiness
          source:
            code: local
            branch: v3.0.0_gcr
            requirements:
              - pandas==1.5.3

        - step: inference
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/gdnn.git
            branch: main
            requirements:
              - pandas==1.5.3
              - torch==2.0.0
              - requirements.txt
        
        - step: output
          source:
            code: local
            branch: output_dev
            requirements:
              - requirements.txt

     
control:
    ## 1. 패키지 설치 및 asset 존재 여부를 실험 시마다 체크할지, 한번만 할지 결정
    ## 1-2 requirements.txt 및 종속 패키지들 한번만 설치할 지 매번 설치할지도 결정 
    - get_asset_source: once ## once, every
    ## 2. 생성된 artifacts 를 backup 할지를 결정 True/False
    - backup_artifacts: True
    ## 3. pipeline 로그를 backup 할지를 결정 True/False
    - backup_log: True
    ## 4. 저장 공간 사이즈를 결정 (단위 MB)
    - backup_size: 1000
    ## 5. Asset 사이 데이터 전달 방법으로 memory, file 를 지원
    - interface_mode: memory

ui_args_detail:
    - train_pipeline:
        - step: input
          args:
              - name: file_type
                description: 입력 데이터의 포맷을 지정합니다. 현재 csv만 지원됩니다.
                type: string
                default: ''
                range:
                  - 1
                  - 1000000
              - name: encoding
                description: 입력 데이터의 인코딩 방식을 지정합니다. 현재 utf-8만 지원됩니다.
                type: string
                default: ''
                range:
                  - 1
                  - 1000000

        - step: readiness
          args:
              - name: drop_columns
                description: 학습에서 제외할 컬럼들을 기입합니다. ex) x3, x4 또는 하나도 제외하지 않으려면 none
                type: string
                default: ''
                range:
                  - 1
                  - 1000000
              - name: y_column
                description: GCR 지도학습에 사용 될 라벨 컬럼명을 기입합니다. ex) y
                type: string
                default: ''
                range:
                  - 1
                  - 1000000

        - step: graph
          args:
              - name: dimension
                description: embedding vector의 차원 수를 기입합니다. (dimension>1 & even)
                type: int
                default: 64
                range:
                  - 2
                  - 1024
              - name: num_epochs
                description: 학습 epoch 수를 기입합니다.
                type: int
                default: 10
                range:
                  - 1
                  - 50

        - step: train
          args:
              - name: task
                description: classification과 regression 중 하나를 입력합니다.
                type: single_selection
                default: classification
                selectable:
                  - classification
                  - regression
              - name: epochs
                description: DNN 학습 시 epoch 수를 선택합니다.
                type: int
                default: 10
                range:
                  - 1
                  - 1000

    - inference_pipeline:
        - step: input
          args:
              - name: file_type
                description: 입력 데이터의 포맷을 지정합니다. 현재 csv만 지원됩니다.
                type: string
                default: ''
                range:
                  - 1
                  - 1000000
              - name: encoding
                description: 입력 데이터의 인코딩 방식을 지정합니다. 현재 utf-8만 지원됩니다.
                type: string
                default: ''
                range:
                  - 1
                  - 1000000

        - step: readiness
          args:
              - name: drop_columns
                description: 학습에서 제외할 컬럼들을 기입합니다. ex) x3, x4 또는 하나도 제외하지 않으려면 none
                type: string
                default: ''
                range:
                  - 1
                  - 1000000
