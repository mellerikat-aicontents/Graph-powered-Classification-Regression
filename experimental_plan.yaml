## load data from external_path
name: GCR
version: 2.2.0

external_path:
    - load_train_data_path: ./solution/sample_data/train
    - load_inference_data_path: ./solution/sample_data/test
    - save_train_artifacts_path:
    - save_inference_artifacts_path:
    - load_model_path: 

external_path_permission:
    - aws_key_profile:
 
## Parameter setting for experiment 
## 
user_parameters:
    - train_pipeline:
        - step: input
          args:
            - file_type: csv               # (str) csv (default) | parquet
              encoding: utf-8              # (str) utf-8 (default) | euc-kr | utf-16 | ascii | cp949
              # NOTE - AI advisor supports only csv and utf-8 for now.
          ui_args:
            - file_type
            - encoding

        - step: readiness
          args:
            - x_columns:                   # (list of str) [''] (default) | list of column names
              drop_columns:                # (list of str) [''] (default) | list of column names
              y_column: target             # (str) a column name
          ui_args:
            - x_columns
            - drop_columns
            - y_column

        - step: graph
          args:       
            - 
              dimension: 32                # (int), 32(default), dimension > 1 & even
              num_epochs: 10               # (int), 10(default)
              num_partitions: 1            # (int), 1(default)
              use_gpu: False               # (bool), False(default) | True
          ui_args:
            - dimension
            - num_epochs
            - num_partitions
        
        - step: train
          args:
            - task: classification         # (str), classification(default) | regression
              eval_metric: accuarcy        # (str), accuracy | precision | recall | f1_score (default) | fbeta_score | rmse (regression)
              fbeta: 0.5                   # (float), 0 < fbeta < inf
              target_label:                # (str, int, float), A value of any type or Empty for all labels
              #target_label: 1              # (str, int, float), A value of any type or Empty for all labels
              num_hpo: 20                  # (int), 20(default)

          ui_args:
            - task
            - eval_metric
            - num_hpo
        
        - step: output
          args:

    - inference_pipeline:
        - step: input
          args:
            - file_type: csv               # (str) csv (default) | parquet
              encoding: utf-8              # (str) utf-8 (default) | euc-kr | utf-16 | ascii | cp949
              # NOTE - AI advisor supports only csv and utf-8 for now.
          ui_args:
            - file_type
            - encoding

        - step: readiness
          args:
            # NOTE - Just check if the x column list is the same as train pipeline
            - x_columns:                   # (list of str) [''] (default) | list of column names
              drop_columns:                # (list of str) [''] (default) | list of column names
          ui_args:
            - x_columns
            - drop_columns

        - step: inference
          args:
            - global_xai: True             # (bool), True | False (default)
              local_xai: False             # (bool), True | False (default)

          ui_args:
            - global_xai
            - local_xai
        
        - step: output
          args:
   
## asset information       
asset_source:
    - train_pipeline:
        - step: input
          source:  ## git | local 
            code: http://mod.lge.com/hub/dxadvtech/assets/input.git
            branch: v1.0.1_tabular
            requirements:
              - pandas==1.5.3
              - torch==2.0.0
              - numpy==1.26.4
        
        - step: readiness
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/readiness.git
            branch: v2.1.0_gcr
            requirements:
              - pandas==1.5.3

        - step: graph
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/gfe.git
            branch: release-2.2.0
            requirements:
              - torch==2.0.0
              - requirements.txt

        - step: train
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/gdt.git
            branch: release-1.0.0
            requirements:
              - pandas==1.5.3
              - torch==2.0.0
              - requirements.txt
        
        - step: output
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/output.git
            branch: output_dev
            requirements:
              - requirements.txt
   
    - inference_pipeline:
        - step: input
          source:  ## git | local
            code: http://mod.lge.com/hub/dxadvtech/assets/input.git
            branch: v1.0.1_tabular
            requirements:
              - pandas==1.5.3
              - numpy==1.26.4

        - step: readiness
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/readiness.git
            branch: v2.1.0_gcr
            requirements:
              - pandas==1.5.3

        - step: inference
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/gdt.git
            branch: release-1.0.0
            requirements:
              - pandas==1.5.3
              - torch==2.0.0
              - requirements.txt
        
        - step: output
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/output.git
            branch: output_dev
            requirements:
              - requirements.txt
     
control:
    ## 1. 패키지 설치 및 asset 존재 여부를 실험 시마다 체크할지, 한번만 할지 결정
    ## 1-2 requirements.txt 및 종속 패키지들 한번만 설치할 지 매번 설치할지도 결정 
    - get_asset_source: once ## once, every
    # TODO 아래 get_external_data 제작하기
    #- get_external_data: every ## once, every  # Supported until ALO 2.2.1
    ## 2. 생성된 artifacts 를 backup 할지를 결정 True/False
    - backup_artifacts: True
    ## 3. pipeline 로그를 backup 할지를 결정 True/False
    - backup_log: True
    ## 4. 저장 공간 사이즈를 결정 (단위 MB)
    - backup_size: 1000
 
    ## 5. Asset 사이 데이터 전달 방법으로 memory, file 를 지원
    - interface_mode: memory

ui_args_detail:
    - train_pipeline:
        - step: input
          args:
              - name: file_type
                description: 입력 데이터의 포맷을 지정합니다. 현재 csv만 지원됩니다.
                type: string
                default: ''
                range:
                  - 1
                  - 1000000
              - name: encoding
                description: 입력 데이터의 인코딩 방식을 지정합니다. 현재 utf-8만 지원됩니다.
                type: string
                default: ''
                range:
                  - 1
                  - 1000000

        - step: readiness
          args:
              - name: x_columns
                description: GCR 모델링에 사용할 x 컬럼들을 기입합니다. ex) x1, x2 또는 모든 x 컬럼들을 지정하려면 빈칸
                type: string
                default: ''
                range:
                  - 1
                  - 1000000
              - name: drop_columns
                description: 위 x_columns 중 제외할 컬럼들을 기입합니다. ex) x3, x4 또는 하나도 제외하지 않으려면 빈칸
                type: string
                default: ''
                range:
                  - 1
                  - 1000000
              - name: y_column
                description: GCR 지도학습에 사용 될 라벨 컬럼명을 기입합니다. ex) y
                type: string
                default: ''
                range:
                  - 1
                  - 1000000
#              - name: groupkey_columns
#                description: 나누어 추론할 데이터를 구분하는 groupkey 컬럼들을 기입합니다. ex) key1, key2 또는 없으면 none
#                type: string
#                default: ''
#                range:
#                  - 1
#                  - 1000000

        - step: graph
          args:
              - name: dimension
                description: embedding vector의 차원 수를 기입합니다. (dimension>1 & even)
                type: int
                default: 256
                range:
                  - 2
                  - 1024
              - name: num_epochs
                description: 학습 epoch 수를 기입합니다.
                type: int
                default: 10
                range:
                  - 1
                  - 100
              - name: num_partitions
                description: 전체 데이터를 몇 개로 나누어 embedding할지 기입합니다.
                type: int
                default: 1
                range:
                  - 1
                  - 512

        - step: train
          args:
              - name: task
                description: classification과 regression 중 하나를 입력합니다.
                type: single_selection
                default: classification
                selectable:
                  - classification
                  - regression
              - name: eval_metric
                description: GCR 학습 시 best 모델 선정 기준을 선택합니다.
                type: single_selection
                default: f1_score
                selectable:
                  - accuracy
                  - precision
                  - recall
                  - f1_score
              - name: num_hpo
                description: GCR 학습 시 HPO 횟수를 선택합니다.
                type: int
                default: 20
                range:
                  - 1
                  - 1000

    - inference_pipeline:
        - step: input
          args:
              - name: file_type
                description: 입력 데이터의 포맷을 지정합니다. 현재 csv만 지원됩니다.
                type: string
                default: ''
                range:
                  - 1
                  - 1000000
              - name: encoding
                description: 입력 데이터의 인코딩 방식을 지정합니다. 현재 utf-8만 지원됩니다.
                type: string
                default: ''
                range:
                  - 1
                  - 1000000

        - step: readiness
          args:
              - name: x_columns
                description: GCR 모델링에 사용할 x 컬럼들을 기입합니다. ex) x1, x2 또는 모든 x 컬럼들을 지정하려면 빈칸
                type: string
                default: ''
                range:
                  - 1
                  - 1000000
              - name: drop_columns
                description: 위 x_columns 중 제외할 컬럼들을 기입합니다. ex) x3, x4 또는 하나도 제외하지 않으려면 빈칸
                type: string
                default: ''
                range:
                  - 1
                  - 1000000
#              - name: groupkey_columns
#                description: 나누어 추론할 데이터를 구분하는 groupkey 컬럼들을 기입합니다. ex) key1, key2 또는 없으면 none
#                type: string
#                default: ''
#                range:
#                  - 1
#                  - 1000000

        - step: inference
          args:
              - name: global_xai
                description: Global Graph XAI 제공 여부를 선택합니다.
                type: single_selection
                default: False
                selectable:
                  - True
                  - False
              - name: local_xai
                description: Local Graph XAI 제공 여부를 선택합니다.
                type: single_selection
                default: False
                selectable:
                  - True
                  - False
