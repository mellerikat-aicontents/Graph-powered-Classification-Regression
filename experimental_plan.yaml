## load data from external_path
name: Graph Classification/Regression # GCR 2.1.0 # ALO 2.2.1

external_path:
    - load_train_data_path: ./solution/sample_data/train
    - load_inference_data_path: ./solution/sample_data/test
    - save_train_artifacts_path:
    - save_inference_artifacts_path:
    - load_model_path: 

external_path_permission:
    - aws_key_profile:  # ALO 2.2.1
#    - s3_private_key_file:  # ALO 2.2
 
## Parameter setting for experiment 
## 
user_parameters:
    - train_pipeline:
        - step: input
          args:
            - input_path: train            # (str)
              x_columns:                   # (list)
              use_all_x: True              # (bool), True | False
              y_column: TRAIN_LABEL        # (str) 
              drop_columns:
              encoding:                    # (str), utf-8(default) | cp949
          ui_args:
            - x_columns
            - y_column

        - step: readiness
          args:
            - x_columns:                   # (list of str)
              y_column: TRAIN_LABEL        # (str)
              groupkey_columns:            # (list of str)
              center_node_column: Lead_No  # (str)

        - step: graph
          args:       
            - dimension: 32                # (int), 64(default), dimension > 1 & even
              num_epochs: 10               # (int), 10(default)
              num_partitions:              # (int), 1(default)
              use_gpu:                     # (bool), False(default) | True
          ui_args:
            - dimension
            - num_epochs
        
        - step: train
          args:
            - task:                        # (str), classification(default) | regression
              epochs: 10                   # (int), 10(default)
          ui_args:
            - task
            - epochs
        
        - step: output
          args:

                                                      
    - inference_pipeline:
        - step: input
          args:
            - input_path: test         # (str)
              x_columns:               # (list)
              use_all_x: True          # (bool), True | False 
              y_column: 
              drop_columns:
              encoding:  
          ui_args:
            - x_columns

        - step: readiness
          args:
            - x_columns:                # (list of str)
              y_column:                 # (str)
              groupkey_columns:         # (list of str)
              center_node_column: Lead_No    # (str)

        - step: inference
          args:
        
        - step: output
          args:

   
## asset information       
asset_source:
    - train_pipeline:
        - step: input
          source:  ## git | local 
            code: http://mod.lge.com/hub/smartdata/ml-framework/alov2-module/input.git
            # code: local
            branch: tabular_2.0
            requirements:
              - pandas==1.5.3
        
        - step: readiness
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/readiness.git
            # code: local
            branch: gcr-0.9.0
            requirements:
              - pandas==1.5.3

        - step: graph
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/gfe.git
            # code: local
            branch: feature/dnn
            requirements:
              - torch==2.0.0
              - requirements.txt

        - step: train
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/gdt.git
            branch: release-1.0.0
            requirements:
              - pandas==1.5.3
              - torch==2.0.0
              - requirements.txt
        
        - step: output
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/output.git
            # code: local
            branch: output_dev
            requirements:
              - requirements.txt


   
    - inference_pipeline:
        - step: input
          source:  ## git | local
           # code: http://mod.lge.com/hub/smartdata/ml-framework/alov2-module/input.git
            code: local
            branch: tabular_2.0
            requirements:
              - pandas==1.5.3

        - step: readiness
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/readiness.git
            # code: local
            branch: gcr-0.9.0
            requirements:
              - pandas==1.5.3

        - step: inference
          source:
            code: http://mod.lge.com/hub/dxadvtech/assets/gdt.git
            branch: release-1.0.0
            requirements:
              - pandas==1.5.3
              - torch==2.0.0
              - requirements.txt
        
        - step: output
          source:
            #code: http://mod.lge.com/hub/dxadvtech/assets/output.git
            code: local
            branch: output_dev
            requirements:
              - requirements.txt

     
control:
    ## 1. 패키지 설치 및 asset 존재 여부를 실험 시마다 체크할지, 한번만 할지 결정
    ## 1-2 requirements.txt 및 종속 패키지들 한번만 설치할 지 매번 설치할지도 결정 
    - get_asset_source: once ## once, every
    # TODO 아래 get_external_data 제작하기
    - get_external_data: every ## once, every
    ## 2. 생성된 artifacts 를 backup 할지를 결정 True/False
    - backup_artifacts: True
    ## 3. pipeline 로그를 backup 할지를 결정 True/False
    - backup_log: True
    ## 4. 저장 공간 사이즈를 결정 (단위 MB)
    - backup_size: 1000
 
    ## 5. Asset 사이 데이터 전달 방법으로 memory, file 를 지원
    - interface_mode: memory
