{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "194fe113-d67a-476d-ae96-7f72605a4af1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Jupyter Notebook for GCR**\n",
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a9faf9-02ec-4c90-9af4-dfe0f02f29cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Table of Content**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbe8002-b1cf-432b-8a26-4e8472c83df9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    ">### 0. Introduction\n",
    ">### 1. 환경 구성\n",
    ">### 2. Train Workflow\n",
    ">### 3. Inference Workflow\n",
    ">### 4. Batch Running\n",
    ">### 5. 문의 및 기능 개발 요청\n",
    ">### 6. References   \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adcc16c-5678-4a69-9a45-9f46f6162e44",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **0. Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d751b6-26d5-4ec6-bd94-f44dc1599898",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 본 sample notebook은 GCR의 구조와 각 asset의 역할과 산출물, 그 사용법을 처음 접하는 분들이 알기 쉽게 이해할 수 있도록 제작되었습니다.   \n",
    "\n",
    "[ **1. 환경 구성** ]에서는 ALO 등 환경 설치 방법을 설명하고,   \n",
    "[ **2. Train workflow** ]와 [ **3. Inference workflow** ]는 각각 train workflow와 inference workflow의 사용 방법과 산출물을 설명하며,   \n",
    "[ **4. Batch running** ]에서는 sample notebook이 아닌 실제 과제 운용 시에 GCR contents를 수행하는 방법을 설명하고   \n",
    "[ **5. 문의 및 기능 개발 요청** ]에서는 사용 중 문의 사항이나 기능에 대한 수정/개발 요청 방법을,   \n",
    "[ **6. References** ]에서는 추가로 참고하실 collab 문서 등에 대한 links를 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a97420-7def-4cf2-ae32-51ee8fbdf4fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Notebook의 Workflow는 다음과 같이 구성됩니다.\n",
    "> Workflow NAME (ex. Train Workflow)\n",
    "\n",
    ">> Workflow 구성 설명\n",
    ">>> **A** asset : A asset 설명   \n",
    ">>> **B** asset : B asset 설명   \n",
    ">>> ...\n",
    "\n",
    ">> Workflow Setup \n",
    ">>> Workflow Setup 코드\n",
    "\n",
    ">> [0] **A** asset\n",
    ">>> parameter 설명 및 실행 코드 \n",
    "\n",
    ">> [1] **B** asset\n",
    ">>> parameter 설명 및 실행 코드\n",
    "\n",
    ">> ..\n",
    "\n",
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f392e9ef-2821-4b89-9499-9d7932f2d0b3",
   "metadata": {},
   "source": [
    "#### 각 Asset은 동작확인을 위해 다음과 같이 구성됩니다.\n",
    "> ASSET NAME\n",
    "\n",
    ">> 주요 Parameter 설명\n",
    ">>> param1: param1 설명   \n",
    ">>> ***param2***: param2 설명 [*option1 / option2 / option3*]   \n",
    ">>> param3: param3 설명 [*option1 / option2*]   \n",
    ">>> ..\n",
    "\n",
    ">> Parameter 설정부\n",
    ">>> #################   \n",
    ">>> parameter 설정 코드   \n",
    ">>> #################   \n",
    "\n",
    ">> Asset 실행부\n",
    ">>> #################   \n",
    ">>> Asset 실행 코드   \n",
    ">>> #################   \n",
    "\n",
    "Asset 별로 experimental_plan.yaml에 주어진 parameter에 대한 설명이 주어집니다.   \n",
    "설명에 따라 parameter 변경 시 experimental_plan.yaml을 직접 수정하거나, Parameter 설정부에서 코드 실행을 통해 바꿀 수 있습니다.   \n",
    "위에서 param2와 같이 ***Bold Italic***으로 표기된 변수는 필수 설정 변수로, 최초 실행 또는 데이터가 바뀔 시 꼭 다시 설정해주어야 하는 변수를 의미합니다.   \n",
    "설정된 parameter로 asset을 실행할 수 있습니다. 또한 Parameter를 변경해가며 Asset 실행 결과 변화를 관찰할 수 있습니다.\n",
    "\n",
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d624da5c-a13c-4d2d-946a-697c7aced3f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **1. 환경 구성**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3858a5e5-db47-49aa-bcf6-08fcb4561ed2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### GCR을 사용하기 위해서는 아래와 같은 방법으로 데이터를 준비해야 합니다.\n",
    "> 1. Train, Inference 두 개의 데이터셋을 준비합니다.\n",
    "> 2. 각 데이터에 FLAG_TRAIN_INFERENCE 컬럼을 추가합니다. \n",
    ">    - 각 'Train', 'Inference'가 flag로 들어가야 합니다.\n",
    "> 3. 두 데이터를 합쳐 하나의 데이터셋으로 구성합니다.\n",
    "\n",
    "***GCR은 결측치와 범주형 데이터에 대한 전처리가 필요하지 않습니다***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e07bc62-da8e-4304-80b5-0790dbbdb0b2",
   "metadata": {},
   "source": [
    "#### ALO 설치 및 configuration 설정 방법은 다음과 같습니다.\n",
    "\n",
    "1. 최상위 디렉토리에서 install.sh를 실행합니다\n",
    "> source install.sh\n",
    "2. install.sh를 실행하면 alo 디렉토리가 설치됩니다.\n",
    "3. 가상환경을 설치 및 실행합니다.\n",
    "> conda create -n gcr python=3.10   \n",
    "> conda init bash   \n",
    "> conda activate gcr    \n",
    "3. alo/config 디렉토리로 이동하여 experimental_plan.yaml 파일을 오픈합니다.\n",
    "4. external_path의 load_train_data_path에 아래와 같이 사용할 데이터의 경로(디렉토리)를 입력합니다.\n",
    "\n",
    ">```\n",
    ">external_path:\n",
    ">    - load_train_data_path: /nas001/gcr_test_data/sample/\n",
    ">    - load_inference_data_path:\n",
    ">    - save_train_artifacts_path:\n",
    ">    - save_inference_artifacts_path:\n",
    ">```\n",
    "\n",
    "5. 필수 변경 parameter를 변경합니다. 나머지 parameter는 컨텐츠 yaml에 제공된 default 값을 사용해도 괜찮습니다.\n",
    "6. 아래 **ALO Setup**을 실행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362b6b5c-8668-46b6-b5d8-00888c5580fa",
   "metadata": {},
   "source": [
    "### ALO Setup\n",
    "라이브러리 설치 및 컨텐츠 다운로드를 위해 아래 코드를 실행 해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137cd365-9ed9-4941-aa2e-67fca06e1a4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "os.chdir(os.path.abspath(os.path.join('./alo')))\n",
    "\n",
    "from src.alo import ALO\n",
    "from src.alo import AssetStructure\n",
    "alo = ALO(); alo.set_proc_logger(); alo.preset()\n",
    "pipelines = list(alo.asset_source.keys())\n",
    "\n",
    "from src.external import external_load_data, external_save_artifacts\n",
    "def run(step, pipeline, asset_structure):\n",
    "    # 반복되는 작업을 함수로 변환\n",
    "    asset_config = alo.asset_source[pipeline]\n",
    "    return alo.process_asset_step(asset_config[step], step, pipeline, asset_structure)\n",
    "\n",
    "# pipeline list 를 가지고 옴\n",
    "pipelines = list(alo.asset_source.keys())\n",
    "pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7337fdb-836f-4519-869b-76c6089743d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **2. Train Workflow**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4171f4e9-d318-47ec-8374-f49fb6b30356",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### GCR의 Train Workflow 구성은 다음과 같습니다.\n",
    "> **[0]** Input asset : *사용자가 지정한 경로로부터 데이터를 Import*   \n",
    "> **[1]** Graph asset : *데이터를 토대로 그래프를 구성하고 필요한 임베딩 추출*   \n",
    "> **[2]** Preprocess asset : *(필요시) 결측치 처리 및 라벨 인코딩*   \n",
    "> **[3]** Sampling asset : *(필요시) Imbalance 데이터의 Undersampling*   \n",
    "> **[4]** Train asset : *ML 모델 학습*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2425131a-066e-40e4-99d9-d90e3c858fac",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Train Workflow Setup\n",
    "아래 코드를 실행하여 Train Workflow에 필요한 라이브러리를 먼저 설치 해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7d0f4d-05da-40d0-9b5d-75c496b5794a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alo.external_load_data(pipelines[0]) # external load data for train_pipeline\n",
    "# 사용하는 pipeline의 package를 설치\n",
    "# train = 0, infernence = 1을 선택해야 하고 둘다 설치 해야함\n",
    "pipeline = pipelines[0]\n",
    "alo.install_steps(pipeline, alo.control[\"get_asset_source\"])\n",
    " # 초기 data structure 구성\n",
    "alo.set_asset_structure()\n",
    "init_asset_structure = copy.deepcopy(alo.asset_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c18b98-847e-4c58-848c-bec26204375f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [0] Input asset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9f36d6-84e0-440e-80d3-b462254b006a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 주요 Parameter\n",
    "- ***input_path*** : Extenal Path에서 받은 데이터는 *alo/input/train*에 저장됩니다. 이 중에서 사용할 데이터가 저장된 디렉터리 명을 작성해주시면 됩니다.\n",
    "- x_columns : 데이터의 모든 컬럼을 활용하지 않는 경우엔 직접 선택해서 사용할 수 있습니다.\n",
    "- use_all_x : 데이터의 모든 컬럼을 사용하는 경우 True로 설정하고 사용합니다. 이 경우 x_columns는 빈칸이어야 합니다. [*True / False*]\n",
    "- ***y_column*** : Classification, Regression을 위해서는 Label이 있어야 합니다. Label에 해당하는 컬럼을 작성합니다.\n",
    "- groupkey_columns : 특정 컬럼 명을 기준으로 데이터를 그룹으로 나누어 모델링을 하고 싶을 경우에 사용합니다.\n",
    "- drop_columns : use_all_x가 True일 때 삭제하고 싶은 컬럼을 입력합니다.\n",
    "- time_column : 데이터에 시간 컬럼이 있을 경우 입력합니다.\n",
    "- concat_dataframes : 같은 형태 csv 파일 여러 개를 input data로 불러올 시, concat 여부를 선택합니다. [*True / False*]\n",
    "- encoding : pd.read_csv() 시에 사용할 encoding 방법을 설정합니다.\n",
    "\n",
    "#### Parameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e2c80e-0a14-4e19-b50f-2aa621aec2da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GCR asset 순서에 따라 step 순서를 입력합니다. (input(0) - graph(1) - preprocess(2) - sampling(3) - train(4))\n",
    "step = 0\n",
    "alo.asset_structure= copy.deepcopy(init_asset_structure)\n",
    "alo.asset_structure.args = alo.get_args(pipeline, step)\n",
    "\n",
    "# 아래 주석을 풀어 input asset argument를 원하는 값으로 수정합니다. \n",
    "#asset_structure.args['x_columns'] = ['']\n",
    "alo.asset_structure.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017bbb5c-b15e-4b8b-98c9-9b355da55263",
   "metadata": {},
   "source": [
    "#### Input asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac5a67f-02e5-49f5-9d44-34f24b08baaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_asset_structure = run(step, pipeline, alo.asset_structure)\n",
    "\n",
    "# input asset의 결과 dataframe은 input_asset_structure.data['dataframe']으로 확인할 수 있습니다.\n",
    "input_asset_structure.data['dataframe'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e402b7cc-2391-45dd-8a0d-5be4eb8b9b8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [1] Graph asset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b53121",
   "metadata": {},
   "source": [
    "GCR의 가장 핵심이 되는 asset입니다. Raw Data를 임베딩으로 모두 변환하여 별도의 전처리 없이 더 높은 성능의 ML모델을 획득하기 위한 Tool이 됩니다.\n",
    "#### 주요 Parameter\n",
    "- graph_type : 그래프의 구조를 선택할 수 있습니다. radial은 방사형 구조, relational은 관계형 구조입니다. [*radial / relational*]\n",
    "- center_node_column : 방사형 그래프는 중심 컬럼을 기준으로 그래프를 구성합니다. 데이터의 대표가 되는 컬럼을 선택하면 됩니다.(ex. ID, Name 등)\n",
    "- embedding_column : 임베딩의 대상이 되는 컬럼을 선택합니다. 라벨이 center_node_column과 대응하지 않는 경우가 있을 수 있습니다. 이때는 label이 대응하는 컬럼을 embedding column으로 설정합니다.\n",
    "- drop_columns : 그래프 구성에서 제외할 컬럼을 선택합니다.\n",
    "- num_epochs: Embedding 학습을 위한 epoch을 설정합니다.\n",
    "- workers : worker process 수를 설정합니다.\n",
    "- num_partitions : partition 수를 설정합니다. 증가시켜 메모리 사용량을 줄일 수 있습니다.\n",
    "- extra_columns_for_ml : ml 모델 학습에 임베딩 외에 사용될 컬럼을 지정합니다. 도메인 지식에 기반하여 선택할 필요가 있습니다.\n",
    "- custom_connection : 그래프를 활용할 줄 안다면 직접 relation을 정의할 수 있습니다. 자세한 내용은 manual을 참고.\n",
    "\n",
    "#### Parameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05226c4c-981b-46e6-a187-72e3d47433f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCR asset 순서에 따라 step 순서를 입력합니다. (input(0) - graph(1) - preprocess(2) - sampling(3) - train(4))\n",
    "step = 1 \n",
    "alo.asset_structure= copy.deepcopy(input_asset_structure)\n",
    "alo.asset_structure.args = alo.get_args(pipeline, step)\n",
    "\n",
    "# 아래 주석을 풀어 graph asset argument를 원하는 값으로 수정합니다. \n",
    "#asset_structure.args['dimension'] = 128\n",
    "alo.asset_structure.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2084ad",
   "metadata": {},
   "source": [
    "#### Graph asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be198a60-4793-4639-a709-3cb74263d1a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# asset 실행\n",
    "graph_asset_structure=run(step, pipeline, alo.asset_structure)\n",
    "\n",
    "# graph asset의 결과 dataframe은 graph_asset_structure.data['dataframe']으로 확인할 수 있습니다. \n",
    "graph_asset_structure.data['dataframe'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9047dd80-a5c6-4393-aeb3-327e02a73ddd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [2] Preprocess asset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7698dd0-9153-46c0-97d8-6971ab8f3b2c",
   "metadata": {},
   "source": [
    "GCR은 데이터 전처리가 불필요하기 때문에 Preprocess asset의 역할은 크지 않습니다. 다만 사용자가 임베딩 외에 raw data를 학습에 사용하는 경우 (즉, extra_columns_for_ml 설정시) 결측치를 처리하기 위한 용도입니다.\n",
    "#### 주요 Parameter\n",
    "- handling_missing : 결측치 처리 방식을 지정합니다. 'interpolation' 또는 'fill_number' 중에 선택할 수 있으며 GCR에서는 'interpolation'을 권장합니다.\n",
    "- ***handling_encoding_y_column*** : input asset의 y_column과 동일하게 설정합니다. (필수)\n",
    "- ***handling_encoding_y*** : y_column의 인코딩 방식을 설정합니다. GCR에서는 'label'로 설정합니다.\n",
    "- handling_scaling_x : X 컬럼의 scaling 방식을 선택합니다.\n",
    "- load_train_preprocess : False로 설정합니다. (inference workflow 전용)\n",
    "\n",
    "#### Parameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e75b62-dd0c-441a-a8db-eb6d15a4345b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GCR asset 순서에 따라 step 순서를 입력합니다. (input(0) - graph(1) - preprocess(2) - sampling(3) - train(4))\n",
    "step = 2 \n",
    "alo.asset_structure = copy.deepcopy(graph_asset_structure)\n",
    "alo.asset_structure.args = alo.get_args(pipeline, step)\n",
    "\n",
    "# 아래 주석을 풀어 preprocess asset argument를 원하는 값으로 수정합니다. \n",
    "# asset_structure.args['handling_missing'] = dropna\n",
    "alo.asset_structure.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2d78a8-0a32-4f54-aac7-bff907e2ae94",
   "metadata": {},
   "source": [
    "#### Preprocess asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a116e5ee-0eaa-4cad-9e8b-b7452f7068be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# asset 실행\n",
    "preprocess_asset_structure=run(step, pipeline, alo.asset_structure)\n",
    "\n",
    "# preprocess asset의 결과 dataframe은 preprocess_asset_structure.data['dataframe']으로 확인할 수 있습니다.  \n",
    "preprocess_asset_structure.data['dataframe'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0158d579-4e19-401f-8a1b-ac06a92f0e9f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [3] Sampling asset  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd463df-8ac2-4eeb-a020-49f89a05c5a1",
   "metadata": {},
   "source": [
    "데이터 imbalance가 심한경우엔 sampling이 필요할 수 있습니다. 현재는 undersampling만 제공됩니다.\n",
    "#### 주요 Parameter\n",
    "- sampling_type : sampling이 필요한 경우 설정합니다. 필요없는 경우엔 'none'으로 설정합니다. [*none / under*]\n",
    "- sampling_method : sampling 방법을 선택합니다. [*random / cluster / negative*]\n",
    "- label_sampling : 데이터의 Y 라벨을 기준으로 데이터를 그룹핑하여 샘플링을 할 지 선택합니다. [*True / False*]\n",
    "- ignore_label_class : label_sampling이 True일 때, 라벨의 특정 클래스는 샘플링하지 않고 전부 사용하고 싶을 때 사용합니다. EX) Y 라벨 클래스가 'OK' 또는 'NG'일 때 'NG'클래스를 입력할 경우 NG클래스는 샘플링하지 않습니다.\n",
    "- negative_target_class : Negative sampling(sampling_method가 negative일 때)에만 사용되는 argument입니다. 기준이 되는 Y 라벨의 특정 클래스를 기입합니다.\n",
    "- label_sampling_num_type : Y 라벨의 각 클래스에 샘플링할 데이터 수를 계산하기 위한 방법들입니다. [*ratio / number / compare / mingroup*]\n",
    "- label_sampling_num : label_sampilng_num_type에 따라 값을 입력합니다. (user manual 참조)\n",
    "- sampling_groupkey_columns : 특정 컬럼을 기준으로 데이터를 그룹핑하여 샘플링을 할 때 사용합니다. 컬럼명을 list로 입력합니다.\n",
    "- sampling_num_type : 샘플링할 데이터 수를 결정하는 방법입니다. [*ratio / number / compare / mingroup*]\n",
    "- sampling_num : sampling_num_type에 따라 아래 예시의 형식으로 값을 입력합니다. (user manual 참조)\n",
    "\n",
    "#### Parameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20b2f60-8fb3-4115-9006-8bee0b3c5ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GCR asset 순서에 따라 step 순서를 입력합니다. (input(0) - graph(1) - preprocess(2) - sampling(3) - train(4))\n",
    "step = 3 \n",
    "alo.asset_structure = copy.deepcopy(preprocess_asset_structure)\n",
    "alo.asset_structure.args = alo.get_args(pipeline, step)\n",
    "\n",
    "# 아래 주석을 풀어 sampling asset argument를 원하는 값으로 수정합니다. \n",
    "# asset_structure.args['sampling_type'] = 'under'\n",
    "alo.asset_structure.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4230191c-ec22-4e85-9a18-82817a90e2fb",
   "metadata": {},
   "source": [
    "#### Sampling asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025f4f8c-f430-4c28-b8e0-e27e7fe1a0db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# asset 실행\n",
    "sampling_asset_structure=run(step, pipeline, alo.asset_structure)\n",
    "\n",
    "# sampling asset의 결과 dataframe은 sampling_asset_structure.data['dataframe']으로 확인할 수 있습니다.\n",
    "sampling_asset_structure.data['dataframe'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b09311e-a704-425b-8203-180f3033d808",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [4] Train asset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b6a3a7-2204-42b5-8cc8-a5b5f740f457",
   "metadata": {},
   "source": [
    "추출된 임베딩을 활용하여 ML모델을 학습합니다.\n",
    "#### 주요 Parameter\n",
    "- model_type: 목적에 맞는 학습 방식을 선택합니다. (classification/regression)\n",
    "- data_split_method: HPO를 위한 데이터 분할 방식을 선택합니다. (cross_validate/train_test_split)\n",
    "- evaluation_metric: classification의 경우 accuracy, precision, recall, f1-score / regression의 경우 mse, r2, mae, rmse 중 선택합니다.\n",
    "- model_list: lightgbm, random-forest, gbm, Catboost 중 복수 선택 가능합니다.\n",
    "- num_hpo: 설정 범위 내 hpo 횟수를 결정합니다.\n",
    "- param_range: Search 범위를 지정합니다.\n",
    "- shap_ratio: shap value 뽑을 데이터를 sampling 하는 비율을 결정합니다.\n",
    "\n",
    "#### Parameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f0149f-bfb4-4223-835a-769fd57594bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GCR asset 순서에 따라 step 순서를 입력합니다. (input(0) - graph(1) - preprocess(2) - sampling(3) - train(4))\n",
    "step = 4 \n",
    "alo.asset_structure = copy.deepcopy(sampling_asset_structure)\n",
    "alo.asset_structure.args = alo.get_args(pipeline, step)\n",
    "\n",
    "# 아래 주석을 풀어 train asset argument를 원하는 값으로 수정합니다.\n",
    "alo.asset_structure.args['model_list'] = ['lgb']\n",
    "alo.asset_structure.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0c0b28-561d-4815-b4fc-f2078e1a0f59",
   "metadata": {},
   "source": [
    "#### Train asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2a5dcd-b0b8-455d-8b68-3483238a5aae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# asset 실행\n",
    "train_asset_structure=run(step, pipeline, alo.asset_structure)\n",
    "\n",
    "# train asset의 결과 dataframe은 train_asset_structure.data['dataframe']으로 확인할 수 있습니다.\n",
    "train_asset_structure.data['dataframe'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e992948d-2fc0-4d6b-8107-833b7fd67eb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **3. Inference Workflow**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2f82f0-1e6c-4af5-b842-78d428c1e6f3",
   "metadata": {},
   "source": [
    "#### GCR의 Inference Workflow 구성은 다음과 같습니다.\n",
    "> **[0]** Input : *사용자가 지정한 경로로부터 데이터를 Import*   \n",
    "> **[1]** Preprocess : *(필요시) 결측치 처리 및 라벨 인코딩*   \n",
    "> **[2]** Inference : *Train Workflow에서 선택된 베스트 모델을 활용해 라벨 추론*   \n",
    "> **[3]** Result : *결과 출력*   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6707f7c-816f-4c29-86af-be1f2d990f4a",
   "metadata": {},
   "source": [
    "#### Inference Workflow Setup\n",
    "아래 코드를 실행하여 Inference Workflow에 필요한 라이브러리를 먼저 설치 해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e052e1b-3478-47f8-8c6d-62aa4474b591",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 아래는 Inference 시 필요한 라이브러리를 설치하는 코드입니다. library 설치 에러가 발생하면 아래 셀을 재실행 해주세요\n",
    "alo.external_load_data(pipelines[1]) # external load data for train_pipeline\n",
    "# 사용하는 pipeline의 package를 설치\n",
    "# train = 0, infernence = 1을 선택해야 하고 둘다 설치 해야함\n",
    "pipeline = pipelines[1]\n",
    "alo.install_steps(pipeline, alo.control[\"get_asset_source\"])\n",
    " # 초기 data structure 구성\n",
    "alo.set_asset_structure()\n",
    "init_asset_structure = copy.deepcopy(alo.asset_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08d76d2-b3a0-429b-a5de-b74ae6c04176",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [0] Input asset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f681c8a8-ffde-4f59-a694-1b3849b90dd4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 주요 Parameter\n",
    "- input_path : GCR에서는 추론데이터가 'inference' 위치에 자동 저장됩니다. 따로 설정할 필요 없이 주어진 'inference'로 놓고 사용합니다.\n",
    "- x_columns : Inference workflow에서는 x_column을 따로 지정하지 않습니다. None으로 설정합니다.\n",
    "- use_all_x : Inference workflow에서는 use_all_x를 True로 놓습니다.\n",
    "- y_column : 추론데이터는 y_column이 없습니다. None으로 설정합니다.\n",
    "- groupkey_columns : 특정 컬럼 명을 기준으로 데이터를 그룹으로 나누어 모델링을 하고 싶을 경우에 사용합니다.\n",
    "- drop_columns : use_all_x가 True일 때 삭제하고 싶은 컬럼을 입력합니다.\n",
    "- time_column : 데이터에 시간 컬럼이 있을 경우 입력합니다.\n",
    "- concat_dataframes : 같은 형태 csv 파일 여러 개를 input data로 불러올 시, concat 여부를 선택합니다. [*True / False*]\n",
    "- encoding : pd.read_csv() 시에 사용할 encoding 방법을 설정합니다.\n",
    "\n",
    "#### Parameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f43e8e-5a9a-4cbc-b2b5-f548d92b3feb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GCR asset 순서에 따라 step 순서를 입력합니다. (input(0) - preprocess(1) - inference(2) - result(3))\n",
    "step = 0 \n",
    "alo.asset_structure = copy.deepcopy(init_asset_structure)\n",
    "alo.asset_structure.args = alo.get_args(pipeline, step)\n",
    "\n",
    "# 아래 주석을 풀어 input asset argument를 원하는 값으로 수정합니다.\n",
    "# asset_structure.args['x_columns'] = ['']\n",
    "alo.asset_structure.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f705ac75-11a8-4093-9531-3b09de8fc38e",
   "metadata": {},
   "source": [
    "##### Input asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026f2355-99c7-437f-8274-dbed7aa968d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# asset 실행\n",
    "input_asset_structure=run(step, pipeline, alo.asset_structure)\n",
    "\n",
    "# input asset의 결과 dataframe은 input_asset_structure.data['dataframe']으로 확인할 수 있습니다.\n",
    "input_asset_structure.data['dataframe'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9f3b11-9b2d-4bd0-87f2-25b23495758f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [1] Preprocess asset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ddf39d-af5c-48bd-9a96-a3543e030b2c",
   "metadata": {},
   "source": [
    "GCR은 데이터 전처리가 불필요하기 때문에 Preprocess asset의 역할은 크지 않습니다. 다만 사용자가 임베딩 외에 raw data를 학습에 사용하는 경우 (즉, extra_columns_for_ml 설정시) 결측치를 처리하기 위한 용도입니다.\n",
    "#### 주요 Parameter\n",
    "- handling_missing: 결측치 처리 방식을 지정합니다. 'interpolation' 또는 'fill_number' 중에 선택할 수 있으며 GCR에서는 'interpolation'을 권장합니다.\n",
    "- ***handling_encoding_y_column***: None으로 설정합니다.\n",
    "- limit_encoding_categories: onehot이나 hashing 인코딩 진행 시 컬럼이 너무 많아지는 것에 대한 한계치를 설정합니다.\n",
    "- load_train_preprocess: 반드시 True로 설정합니다. train workflow의 preprocess를 참조하여 진행합니다.\n",
    "\n",
    "#### Parameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b486fd42-87de-4c15-aa77-324cb77415b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GCR asset 순서에 따라 step 순서를 입력합니다. (input(0) - preprocess(1) - inference(2) - result(3))\n",
    "step = 1 \n",
    "alo.asset_structure = copy.deepcopy(input_asset_structure)\n",
    "alo.asset_structure.args = alo.get_args(pipeline, step)\n",
    "\n",
    "# 아래 주석을 풀어 preprocess asset argument를 원하는 값으로 수정합니다.\n",
    "# asset_structure.args['x_columns'] = ['']\n",
    "alo.asset_structure.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6a36f8-55c3-4e3e-8879-d8aeb7f9ecac",
   "metadata": {},
   "source": [
    "#### Preprocess asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f690c108-afc0-48e3-9b04-85a4f498c8da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# asset 실행\n",
    "preprocess_asset_structure=run(step, pipeline, alo.asset_structure)\n",
    "\n",
    "# preprocess asset의 결과 dataframe은 preprocess_asset_structure.data['dataframe']으로 확인할 수 있습니다.  \n",
    "preprocess_asset_structure.data['dataframe'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c107ab-179a-4ad9-b3ec-ba5195910eb2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [2] Inference asset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a66a6da-7efd-4c9f-92b4-b91366365db7",
   "metadata": {},
   "source": [
    "#### 주요 Parameter\n",
    "- model_type: Train workflow의 Train asset과 동일하게 classification/regression 중 설정하면 됩니다. [*classification / regression*]\n",
    "- run_shapley: shapley 실행 여부를 선택합니다. [*True / False*]\n",
    "\n",
    "#### Parameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b21092-9b65-4de1-874e-46e8cbd96075",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GCR asset 순서에 따라 step 순서를 입력합니다. (input(0) - preprocess(1) - inference(2) - result(3))\n",
    "step = 2 \n",
    "alo.asset_structure = copy.deepcopy(preprocess_asset_structure)\n",
    "alo.asset_structure.args = alo.get_args(pipeline, step)\n",
    "\n",
    "# 아래 주석을 풀어 inference asset argument를 원하는 값으로 수정합니다.\n",
    "# asset_structure.args['x_columns'] = ['']\n",
    "alo.asset_structure.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5544d75-1e2f-4009-9e24-7cb91bc18ced",
   "metadata": {},
   "source": [
    "#### Inference asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9857de-2615-41ec-829f-cddb0808aab2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# asset 실행\n",
    "inference_asset_structure=run(step, pipeline, alo.asset_structure)\n",
    "\n",
    "# inference asset의 결과 dataframe은 inference_asset_structure.data['dataframe']으로 확인할 수 있습니다.  \n",
    "inference_asset_structure.data['dataframe'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b9e329-d954-411c-9c33-42656d29bf01",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [3] Result asset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e749a64d",
   "metadata": {},
   "source": [
    "#### 주요 Parameter\n",
    "- result_save_name: 결과 저장 파일명을 설정합니다.\n",
    "\n",
    "#### Parameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17905521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCR asset 순서에 따라 step 순서를 입력합니다. (input(0) - preprocess(1) - inference(2) - result(3))\n",
    "step = 3\n",
    "alo.asset_structure = copy.deepcopy(inference_asset_structure)\n",
    "alo.asset_structure.args = alo.get_args(pipeline, step)\n",
    "\n",
    "# 아래 주석을 풀어 result asset argument를 원하는 값으로 수정합니다.\n",
    "# asset_structure.args['x_columns'] = ['']\n",
    "alo.asset_structure.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74c2f5c",
   "metadata": {},
   "source": [
    "#### Result asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c899d49e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# asset 실행\n",
    "result_asset_structure=run(step, pipeline, alo.asset_structure)\n",
    "\n",
    "# result asset의 결과 dataframe은 result_asset_structure.data['dataframe']으로 확인할 수 있습니다.\n",
    "result_asset_structure.data['dataframe'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36aa7cc-9b57-48ea-bec5-2b3cb0c02946",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **4. Batch Running**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ba7a95-1c7b-4e33-8eab-3362dcd7402e",
   "metadata": {},
   "source": [
    "Asset 단위가 아닌 전체 workflows에 대해 한번에 동작 시킬 수 있습니다.\n",
    "> 1. alo 디렉토리로 이동합니다.    \n",
    ">> cd alo    \n",
    "> 2. main.py를 실행합니다. \n",
    ">> python main.py\n",
    "\n",
    "*Sample Notebook에서 반영한 parameter는 experimental_plan.yaml에 반영되지 않습니다.*   \n",
    "*config/experimental_plan.yaml을 직접 수정하여 사용하시길 바랍니다.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a35634d-a522-4903-bc86-a89bb7303d90",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **5. 문의 및 기능 개발 요청**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7446e64b-5a59-42da-bcb2-bd7ed88e0ec3",
   "metadata": {},
   "source": [
    "사용중 **Issue 발생** 또는 **기능 요청** 건이 있으실 경우 아래 CLM을 통해 문의/요청 바랍니다.   \n",
    "CLM : http://clm.lge.com/issue/projects/AICONTENTS\n",
    "\n",
    "담당자: 공성우 선임, 김정원 연구원\n",
    "\n",
    "*긴급한 건에 대해서는 담당자에게 연락 바랍니다.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf86e25-352f-434e-88b7-4a4d7deff069",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **6. References**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0296eed9-6dc4-4de8-bb8d-d2f81c8014d7",
   "metadata": {},
   "source": [
    "GCR Release Note : http://collab.lge.com/main/x/iIjdgQ\n",
    "\n",
    "User Guide : http://collab.lge.com/main/x/Owo8gg\n",
    "\n",
    "데이터 명세서 : http://collab.lge.com/main/x/QAo8gg\n",
    "\n",
    "알고리즘 설명서 : http://collab.lge.com/main/x/Zgo8gg\n",
    "\n",
    "GCR Contents Git : http://mod.lge.com/hub/dxadvtech/aicontents/gcr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcr",
   "language": "python",
   "name": "gcr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
