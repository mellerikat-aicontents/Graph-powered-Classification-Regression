{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "362b6b5c-8668-46b6-b5d8-00888c5580fa",
   "metadata": {},
   "source": [
    "아래는 ALO 기본 설정 및 라이브러리 설치 코드입니다. library 설치 에러가 발생하면 아래 셀을 재실행 하고, 지속적으로 문제가 있을 시 문의바랍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "137cd365-9ed9-4941-aa2e-67fca06e1a4f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "os.chdir(os.path.abspath(os.path.join('./alo')))\n",
    "from src.alo import ALO\n",
    "from src.alo import AssetStructure\n",
    "alo = ALO(); alo.preset(); pipelines = list(alo.asset_source.keys())\n",
    "from src.external import external_load_data, external_save_artifacts\n",
    "\n",
    "def run(step, pipeline, asset_structure):\n",
    "    # 반복되는 작업을 함수로 변환\n",
    "    asset_config = alo.asset_source[pipeline]\n",
    "    return alo.process_asset_step(asset_config[step], step, pipeline, asset_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4171f4e9-d318-47ec-8374-f49fb6b30356",
   "metadata": {},
   "source": [
    "## Train Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b7d0f4d-05da-40d0-9b5d-75c496b5794a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[2023-11-09 06:47:51,020][PROCESS][INFO]: You did not write any << s3_private_key_file >> in the config yaml file. When you wanna get data from s3 storage, \n",
      "                                 you have to write the s3_private_key_file path or set << ACCESS_KEY, SECRET_KEY >> in your os environment. \n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,025][PROCESS][INFO]:  Start loading external data. << /nas001/users/seongwoo.kong/gcr_test_data/sample/ >>  \n",
      " << sample >> does not exist in << /home/jovyan/gcr/alo/input/ >>. \n",
      " & << get_external_data >> is set as << once >>. \n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,050][PROCESS][INFO]: Start setting-up << input >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,053][PROCESS][INFO]: << input >> asset had already been created at 2023-11-09 06:36:07.478253\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,056][PROCESS][INFO]: Start setting-up << graph >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,058][PROCESS][INFO]: << graph >> asset had already been created at 2023-11-09 06:36:09.138270\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,060][PROCESS][INFO]: Start setting-up << preprocess >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,063][PROCESS][INFO]: << preprocess >> asset had already been created at 2023-11-09 06:36:32.395510\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,065][PROCESS][INFO]: Start setting-up << sampling >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,067][PROCESS][INFO]: << sampling >> asset had already been created at 2023-11-09 06:36:34.795535\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,068][PROCESS][INFO]: Start setting-up << train >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,071][PROCESS][INFO]: << train >> asset had already been created at 2023-11-09 06:36:40.721596\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,075][PROCESS][INFO]: >>> Ignored installing << torch==2.0.0 >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,078][PROCESS][INFO]: >>> Ignored installing << pandas==1.5.3 >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,080][PROCESS][INFO]: >>> Ignored installing << pandas==1.5.3 >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,082][PROCESS][INFO]: >>> Ignored installing << numpy==1.25.2 >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,084][PROCESS][INFO]: >>> Ignored installing << pandas==1.5.3 >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,086][PROCESS][INFO]: >>> Ignored installing << scikit-learn >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,089][PROCESS][INFO]: >>> Ignored installing << matplotlib >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,092][PROCESS][INFO]: ======================================== Start dependency installation : << input >> \u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,094][PROCESS][INFO]: Start checking existence & installing package - pandas==1.5.3 | Progress: ( 1 / 14 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-09 06:47:51,097][PROCESS][INFO]: [OK] << pandas==1.5.3 >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,099][PROCESS][INFO]: ======================================== Start dependency installation : << graph >> \u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,101][PROCESS][INFO]: Start checking existence & installing package - torch==2.0.0 | Progress: ( 2 / 14 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-09 06:47:51,103][PROCESS][INFO]: [OK] << torch==2.0.0 >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,105][PROCESS][INFO]: Start checking existence & installing package - torchbiggraph@git+https://github.com/facebookresearch/PyTorch-BigGraph.git | Progress: ( 3 / 14 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-09 06:47:51,107][PROCESS][INFO]: [OK] << torchbiggraph@git+https://github.com/facebookresearch/PyTorch-BigGraph.git >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,109][PROCESS][INFO]: ======================================== Start dependency installation : << preprocess >> \u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,111][PROCESS][INFO]: Start checking existence & installing package - category_encoders | Progress: ( 4 / 14 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-09 06:47:51,113][PROCESS][INFO]: [OK] << category_encoders >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,115][PROCESS][INFO]: ======================================== Start dependency installation : << sampling >> \u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,117][PROCESS][INFO]: Start checking existence & installing package - numpy==1.25.2 | Progress: ( 5 / 14 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-09 06:47:51,119][PROCESS][INFO]: [OK] << numpy==1.25.2 >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,121][PROCESS][INFO]: Start checking existence & installing package - scikit-learn | Progress: ( 6 / 14 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-09 06:47:51,123][PROCESS][INFO]: [OK] << scikit-learn >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,125][PROCESS][INFO]: Start checking existence & installing package - umap-learn | Progress: ( 7 / 14 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-09 06:47:51,128][PROCESS][INFO]: [OK] << umap-learn >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,130][PROCESS][INFO]: Start checking existence & installing package - matplotlib | Progress: ( 8 / 14 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-09 06:47:51,132][PROCESS][INFO]: [OK] << matplotlib >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,135][PROCESS][INFO]: ======================================== Start dependency installation : << train >> \u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,137][PROCESS][INFO]: Start checking existence & installing package - seaborn | Progress: ( 9 / 14 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-09 06:47:51,139][PROCESS][INFO]: [OK] << seaborn >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,142][PROCESS][INFO]: Start checking existence & installing package - shap | Progress: ( 10 / 14 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-09 06:47:51,145][PROCESS][INFO]: [OK] << shap >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,147][PROCESS][INFO]: Start checking existence & installing package - lightgbm | Progress: ( 11 / 14 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-09 06:47:51,149][PROCESS][INFO]: [OK] << lightgbm >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,153][PROCESS][INFO]: Start checking existence & installing package - catboost | Progress: ( 12 / 14 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-09 06:47:51,155][PROCESS][INFO]: [OK] << catboost >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,157][PROCESS][INFO]: Start checking existence & installing package - ngboost | Progress: ( 13 / 14 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-09 06:47:51,159][PROCESS][INFO]: [OK] << ngboost >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,161][PROCESS][INFO]: ======================================== Start dependency installation : << force-reinstall >> \u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,164][PROCESS][INFO]: Start checking existence & installing package - numpy==1.25.2 --force-reinstall | Progress: ( 14 / 14 total packages ) \u001b[0m\n",
      "\u001b[94m[2023-11-09 06:47:51,165][PROCESS][INFO]: >>> Start installing package - numpy==1.25.2 --force-reinstall\u001b[0m\n",
      "Collecting numpy==1.25.2\n",
      "  Using cached numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Using cached numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.25.2\n",
      "    Uninstalling numpy-1.25.2:\n",
      "      Successfully uninstalled numpy-1.25.2\n",
      "Successfully installed numpy-1.25.2\n",
      "\u001b[94m[2023-11-09 06:48:01,219][PROCESS][INFO]: ======================================== Finish dependency installation \n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 아래는 Train 시 필요한 라이브러리를 설치하는 코드입니다. library 설치 에러가 발생하면 아래 셀을 재실행 해주세요\n",
    "external_load_data(pipelines[0], alo.external_path, alo.external_path_permission, alo.control['get_external_data'])\n",
    "pipeline = pipelines[0]\n",
    "alo.install_steps(pipeline, alo.control[\"get_asset_source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "888f7a15-6cd5-4874-bca3-6a807b3a6241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 data structure 구성\n",
    "envs, args, data, config = {}, {}, {}, {}\n",
    "init_asset_structure = AssetStructure(envs, args, data, config)\n",
    "# logger init\n",
    "alo.set_proc_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9f36d6-84e0-440e-80d3-b462254b006a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train workflow \n",
    "### 0. Input asset \n",
    "##### Input asset의 arguments 수정 및 확인\n",
    "- 필요한경우 input_args의 항목을 ***asset_structure.args[argument명]=value입력*** 을 통해 변경할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90e2c80e-0a14-4e19-b50f-2aa621aec2da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_path': 'sample',\n",
       " 'x_columns': None,\n",
       " 'use_all_x': True,\n",
       " 'y_column': 'is_married',\n",
       " 'groupkey_columns': None,\n",
       " 'drop_columns': None,\n",
       " 'time_column': None,\n",
       " 'concat_dataframes': None,\n",
       " 'encoding': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GCR asset 순서에 따라 step 순서를 입력합니다. (input(0) - graph(1) - preprocess(2) - sampling(3) - train(4))\n",
    "step = 0 \n",
    "asset_structure = copy.deepcopy(init_asset_structure)\n",
    "asset_structure.args = alo.get_args(pipeline, step)\n",
    "\n",
    "# 아래 주석을 풀어 input asset argument를 원하는 값으로 수정합니다. \n",
    "# asset_structure.args['x_columns'] = ['']\n",
    "asset_structure.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017bbb5c-b15e-4b8b-98c9-9b355da55263",
   "metadata": {},
   "source": [
    "##### Input asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ac5a67f-02e5-49f5-9d44-34f24b08baaf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-11-09 06:48:02,253][USER][INFO][train_pipeline][input]: >> Load path : ['/home/jovyan/gcr/alo//input/train/sample/']\n",
      "[2023-11-09 06:48:02,274][USER][INFO][train_pipeline][input]: >> The file for batch data has been loaded. (File name: /home/jovyan/gcr/alo//input/train/sample/customers.csv)\n",
      "[2023-11-09 06:48:02,277][USER][INFO][train_pipeline][input]: You set the << use_all_x >> as << True >> in the yaml file. So skip checking dataframe columns existence.\n",
      "[2023-11-09 06:48:02,280][USER][INFO][train_pipeline][input]: ==================== Success loading dataframe ====================\n",
      "[2023-11-09 06:48:02,283][USER][INFO][train_pipeline][input]: >> Start processing ignore columns & drop columns: ['/home/jovyan/gcr/alo//input/train/sample/customers.csv']\n",
      "[2023-11-09 06:48:02,286][USER][INFO][train_pipeline][input]: >> You set the << use_all_x >> parameter as << True >> in your config yaml. (So, these x_columns are used: ['name', 'age', 'FLAG_TRAIN_INFERENCE', 'job', 'spent', 'hobbies', 'orders', 'gender', 'address'] )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[2023-11-09 06:48:02,249][ASSET][INFO][train_pipeline][input]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-09 06:48:02\n",
      "- current step      : input\n",
      "- asset branch.     : tabular_2.0\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path'])\n",
      "- load args. keys   : dict_keys(['input_path', 'x_columns', 'use_all_x', 'y_column', 'groupkey_columns', 'drop_columns', 'time_column', 'concat_dataframes', 'encoding'])\n",
      "- load config. keys : dict_keys(['meta'])\n",
      "- load data keys    : dict_keys([])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:48:02,287][ASSET][INFO][train_pipeline][input]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-09 06:48:02\n",
      "- current step      : input\n",
      "- save config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:48:02,289][PROCESS][INFO]: ==================== Finish pipeline: train_pipeline / step: input\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>orders</th>\n",
       "      <th>spent</th>\n",
       "      <th>job</th>\n",
       "      <th>hobbies</th>\n",
       "      <th>is_married</th>\n",
       "      <th>FLAG_TRAIN_INFERENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jasmine_Young</td>\n",
       "      <td>TN17745</td>\n",
       "      <td>female</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>233.44</td>\n",
       "      <td>Receptionist</td>\n",
       "      <td>Photography</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jeffery_Robinson</td>\n",
       "      <td>CT69980</td>\n",
       "      <td>male</td>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "      <td>264.70</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>Fishing</td>\n",
       "      <td>True</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Steven_Sullivan</td>\n",
       "      <td>CT13314</td>\n",
       "      <td>male</td>\n",
       "      <td>70</td>\n",
       "      <td>13</td>\n",
       "      <td>339.10</td>\n",
       "      <td>Janitor</td>\n",
       "      <td>Hiking</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jay_Williams</td>\n",
       "      <td>TN68283</td>\n",
       "      <td>male</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>70.61</td>\n",
       "      <td>Waitress</td>\n",
       "      <td>Playing musical instruments</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Benjamin_Beck</td>\n",
       "      <td>AE11377</td>\n",
       "      <td>male</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>748.94</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>Playing sports</td>\n",
       "      <td>True</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gregory_Gomez</td>\n",
       "      <td>FM04887</td>\n",
       "      <td>male</td>\n",
       "      <td>75</td>\n",
       "      <td>10</td>\n",
       "      <td>937.97</td>\n",
       "      <td>Unkown</td>\n",
       "      <td>Running</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mary_Harris</td>\n",
       "      <td>KS55063</td>\n",
       "      <td>female</td>\n",
       "      <td>60</td>\n",
       "      <td>12</td>\n",
       "      <td>60.97</td>\n",
       "      <td>Librarian</td>\n",
       "      <td>Reading</td>\n",
       "      <td>True</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jimmy_Smith</td>\n",
       "      <td>AL47190</td>\n",
       "      <td>male</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>468.64</td>\n",
       "      <td>Waitress</td>\n",
       "      <td>Sewing</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kenneth_Rubio</td>\n",
       "      <td>RI07301</td>\n",
       "      <td>male</td>\n",
       "      <td>74</td>\n",
       "      <td>15</td>\n",
       "      <td>482.72</td>\n",
       "      <td>Polic</td>\n",
       "      <td>Dancing</td>\n",
       "      <td>True</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jordan_Simmons</td>\n",
       "      <td>AA06497</td>\n",
       "      <td>female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>156.16</td>\n",
       "      <td>Cashier</td>\n",
       "      <td>Baking</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  address  gender  age  orders   spent           job  \\\n",
       "0     Jasmine_Young  TN17745  female   80       0  233.44  Receptionist   \n",
       "1  Jeffery_Robinson  CT69980    male   42      15  264.70       Teacher   \n",
       "2   Steven_Sullivan  CT13314    male   70      13  339.10       Janitor   \n",
       "3      Jay_Williams  TN68283    male   27       7   70.61      Waitress   \n",
       "4     Benjamin_Beck  AE11377    male   21       9  748.94        Farmer   \n",
       "5     Gregory_Gomez  FM04887    male   75      10  937.97        Unkown   \n",
       "6       Mary_Harris  KS55063  female   60      12   60.97     Librarian   \n",
       "7       Jimmy_Smith  AL47190    male   72       5  468.64      Waitress   \n",
       "8     Kenneth_Rubio  RI07301    male   74      15  482.72         Polic   \n",
       "9    Jordan_Simmons  AA06497  female   41       1  156.16       Cashier   \n",
       "\n",
       "                       hobbies is_married FLAG_TRAIN_INFERENCE  \n",
       "0                  Photography      False                TRAIN  \n",
       "1                      Fishing       True                TRAIN  \n",
       "2                       Hiking      False                TRAIN  \n",
       "3  Playing musical instruments      False                TRAIN  \n",
       "4               Playing sports       True                TRAIN  \n",
       "5                      Running      False                TRAIN  \n",
       "6                      Reading       True                TRAIN  \n",
       "7                       Sewing      False                TRAIN  \n",
       "8                      Dancing       True                TRAIN  \n",
       "9                       Baking      False                TRAIN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_asset_structure=run(step, pipeline, asset_structure)\n",
    "\n",
    "# input asset의 결과 dataframe은 input_asset_structure.data['dataframe']으로 확인할 수 있습니다. \n",
    "input_asset_structure.data['dataframe'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b53121",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "### 1. Graph asset \n",
    "##### Graph asset의 args수정 및 확인\n",
    "- 필요한경우 graph_args의 항목을 ***asset_structure.args[argument명]=value입력*** 을 통해 변경할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05226c4c-981b-46e6-a187-72e3d47433f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'graph_type': None,\n",
       " 'center_node_column': 'name',\n",
       " 'embedding_column': 'name',\n",
       " 'train_inference_column': 'FLAG_TRAIN_INFERENCE',\n",
       " 'drop_columns': [],\n",
       " 'dimension': 64,\n",
       " 'num_epochs': 1,\n",
       " 'workers': None,\n",
       " 'num_partitions': None,\n",
       " 'extra_columns_for_ml': [],\n",
       " 'custom_connection': []}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GCR asset 순서에 따라 step 순서를 입력합니다. (input(0) - graph(1) - preprocess(2) - sampling(3) - train(4))\n",
    "step = 1 \n",
    "asset_structure = copy.deepcopy(input_asset_structure)\n",
    "asset_structure.args = alo.get_args(pipeline, step)\n",
    "\n",
    "# 아래 주석을 풀어 graph asset argument를 원하는 값으로 수정합니다. \n",
    "#asset_structure.args['dimension'] = 128\n",
    "asset_structure.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2084ad",
   "metadata": {},
   "source": [
    "##### Graph asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be198a60-4793-4639-a709-3cb74263d1a4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[2023-11-09 06:48:05,495][ASSET][INFO][train_pipeline][graph]: Successfully got << output path >> for saving your data into csv or jpg file: \n",
      " /home/jovyan/gcr/alo//.train_artifacts/output/graph/ \n",
      " - [NOTE] The names of output file must be fixed as << output.csv, output.jpg >> \u001b[0m\n",
      "\u001b[94m[2023-11-09 06:48:05,498][ASSET][INFO][train_pipeline][graph]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-09 06:48:05\n",
      "- current step      : graph\n",
      "- asset branch.     : release-1.2\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['graph_type', 'center_node_column', 'embedding_column', 'train_inference_column', 'drop_columns', 'dimension', 'num_epochs', 'workers', 'num_partitions', 'extra_columns_for_ml', 'custom_connection'])\n",
      "- load config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns'])\n",
      "- load data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "preprocessing blank space...\n",
      "In __init__: pbg ready\n",
      "[2023-11-09 06:48:05.871124] Using the 7 relation types given in the config\n",
      "[2023-11-09 06:48:05.872113] Searching for the entities in the edge files...\n",
      "[2023-11-09 06:48:05.892368] Entity type address:\n",
      "[2023-11-09 06:48:05.893221] - Found 1000 entities\n",
      "[2023-11-09 06:48:05.893843] - Removing the ones with fewer than 1 occurrences...\n",
      "[2023-11-09 06:48:05.894618] - Left with 1000 entities\n",
      "[2023-11-09 06:48:05.895214] - Shuffling them...\n",
      "[2023-11-09 06:48:05.896314] Entity type name:\n",
      "[2023-11-09 06:48:05.896906] - Found 985 entities\n",
      "[2023-11-09 06:48:05.897475] - Removing the ones with fewer than 1 occurrences...\n",
      "[2023-11-09 06:48:05.898200] - Left with 985 entities\n",
      "[2023-11-09 06:48:05.898803] - Shuffling them...\n",
      "[2023-11-09 06:48:05.899915] Entity type age:\n",
      "[2023-11-09 06:48:05.900494] - Found 63 entities\n",
      "[2023-11-09 06:48:05.901050] - Removing the ones with fewer than 1 occurrences...\n",
      "[2023-11-09 06:48:05.901640] - Left with 63 entities\n",
      "[2023-11-09 06:48:05.902289] - Shuffling them...\n",
      "[2023-11-09 06:48:05.903020] Entity type job:\n",
      "[2023-11-09 06:48:05.903673] - Found 37 entities\n",
      "[2023-11-09 06:48:05.904365] - Removing the ones with fewer than 1 occurrences...\n",
      "[2023-11-09 06:48:05.905039] - Left with 37 entities\n",
      "[2023-11-09 06:48:05.905784] - Shuffling them...\n",
      "[2023-11-09 06:48:05.906473] Entity type hobbies:\n",
      "[2023-11-09 06:48:05.907141] - Found 27 entities\n",
      "[2023-11-09 06:48:05.907780] - Removing the ones with fewer than 1 occurrences...\n",
      "[2023-11-09 06:48:05.908447] - Left with 27 entities\n",
      "[2023-11-09 06:48:05.909100] - Shuffling them...\n",
      "[2023-11-09 06:48:05.909779] Entity type orders:\n",
      "[2023-11-09 06:48:05.910449] - Found 21 entities\n",
      "[2023-11-09 06:48:05.911096] - Removing the ones with fewer than 1 occurrences...\n",
      "[2023-11-09 06:48:05.911758] - Left with 21 entities\n",
      "[2023-11-09 06:48:05.912417] - Shuffling them...\n",
      "[2023-11-09 06:48:05.912949] Entity type gender:\n",
      "[2023-11-09 06:48:05.913500] - Found 2 entities\n",
      "[2023-11-09 06:48:05.914003] - Removing the ones with fewer than 1 occurrences...\n",
      "[2023-11-09 06:48:05.914590] - Left with 2 entities\n",
      "[2023-11-09 06:48:05.915124] - Shuffling them...\n",
      "[2023-11-09 06:48:05.915685] Entity type spent:\n",
      "[2023-11-09 06:48:05.916178] - Found 360 entities\n",
      "[2023-11-09 06:48:05.916721] - Removing the ones with fewer than 1 occurrences...\n",
      "[2023-11-09 06:48:05.917321] - Left with 360 entities\n",
      "[2023-11-09 06:48:05.917887] - Shuffling them...\n",
      "[2023-11-09 06:48:05.919353] Preparing counts and dictionaries for entities and relation types:\n",
      "[2023-11-09 06:48:05.925832] - Writing count of entity type address and partition 0\n",
      "[2023-11-09 06:48:05.929428] - Writing count of entity type name and partition 0\n",
      "[2023-11-09 06:48:05.932550] - Writing count of entity type age and partition 0\n",
      "[2023-11-09 06:48:05.935216] - Writing count of entity type job and partition 0\n",
      "[2023-11-09 06:48:05.937492] - Writing count of entity type hobbies and partition 0\n",
      "[2023-11-09 06:48:05.940028] - Writing count of entity type orders and partition 0\n",
      "[2023-11-09 06:48:05.942263] - Writing count of entity type gender and partition 0\n",
      "[2023-11-09 06:48:05.944585] - Writing count of entity type spent and partition 0\n",
      "[2023-11-09 06:48:05.948237] Preparing edge path /home/jovyan/gcr/alo//.train_artifacts/output/graph/partitions/edges_partitioned_rel_3, out of the edges found in /home/jovyan/gcr/alo/.train_artifacts/output/graph/tsvs/rel_3.tsv\n",
      "[2023-11-09 06:48:05.950049] - Edges will be partitioned in 1 x 1 buckets.\n",
      "[2023-11-09 06:48:07.519548] - Processed 999 edges in total\n",
      "[2023-11-09 06:48:07.521527] Preparing edge path /home/jovyan/gcr/alo//.train_artifacts/output/graph/partitions/edges_partitioned_rel_0, out of the edges found in /home/jovyan/gcr/alo/.train_artifacts/output/graph/tsvs/rel_0.tsv\n",
      "[2023-11-09 06:48:07.523431] - Edges will be partitioned in 1 x 1 buckets.\n",
      "[2023-11-09 06:48:09.450858] - Processed 1000 edges in total\n",
      "[2023-11-09 06:48:09.452863] Preparing edge path /home/jovyan/gcr/alo//.train_artifacts/output/graph/partitions/edges_partitioned_rel_5, out of the edges found in /home/jovyan/gcr/alo/.train_artifacts/output/graph/tsvs/rel_5.tsv\n",
      "[2023-11-09 06:48:09.454812] - Edges will be partitioned in 1 x 1 buckets.\n",
      "[2023-11-09 06:48:11.061722] - Processed 1000 edges in total\n",
      "[2023-11-09 06:48:11.063439] Preparing edge path /home/jovyan/gcr/alo//.train_artifacts/output/graph/partitions/edges_partitioned_rel_8, out of the edges found in /home/jovyan/gcr/alo/.train_artifacts/output/graph/tsvs/rel_8.tsv\n",
      "[2023-11-09 06:48:11.065114] - Edges will be partitioned in 1 x 1 buckets.\n",
      "[2023-11-09 06:48:12.636000] - Processed 1000 edges in total\n",
      "[2023-11-09 06:48:12.637777] Preparing edge path /home/jovyan/gcr/alo//.train_artifacts/output/graph/partitions/edges_partitioned_rel_4, out of the edges found in /home/jovyan/gcr/alo/.train_artifacts/output/graph/tsvs/rel_4.tsv\n",
      "[2023-11-09 06:48:12.639564] - Edges will be partitioned in 1 x 1 buckets.\n",
      "[2023-11-09 06:48:14.181783] - Processed 1000 edges in total\n",
      "[2023-11-09 06:48:14.183738] Preparing edge path /home/jovyan/gcr/alo//.train_artifacts/output/graph/partitions/edges_partitioned_rel_7, out of the edges found in /home/jovyan/gcr/alo/.train_artifacts/output/graph/tsvs/rel_7.tsv\n",
      "[2023-11-09 06:48:14.185748] - Edges will be partitioned in 1 x 1 buckets.\n",
      "[2023-11-09 06:48:15.821049] - Processed 985 edges in total\n",
      "[2023-11-09 06:48:15.823048] Preparing edge path /home/jovyan/gcr/alo//.train_artifacts/output/graph/partitions/edges_partitioned_rel_2, out of the edges found in /home/jovyan/gcr/alo/.train_artifacts/output/graph/tsvs/rel_2.tsv\n",
      "[2023-11-09 06:48:15.825061] - Edges will be partitioned in 1 x 1 buckets.\n",
      "[2023-11-09 06:48:17.415191] - Processed 1000 edges in total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda/envs/gcr/lib/python3.10/site-packages/torchbiggraph/util.py:222: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = tensor.storage_type()._new_shared(size.numel())\n",
      "/home/jovyan/conda/envs/gcr/lib/python3.10/site-packages/torch/storage.py:959: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  if self.device.type not in ['cpu', 'cuda']:\n",
      "/home/jovyan/conda/envs/gcr/lib/python3.10/site-packages/torch/storage.py:962: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  module = torch if self.device.type == 'cpu' else torch.cuda\n",
      "/home/jovyan/conda/envs/gcr/lib/python3.10/site-packages/torch/storage.py:985: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  untyped_storage = torch.UntypedStorage._new_shared(size * cls()._element_size())\n",
      "/home/jovyan/conda/envs/gcr/lib/python3.10/site-packages/torch/storage.py:986: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return cls(wrap_storage=untyped_storage)\n",
      "/home/jovyan/conda/envs/gcr/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/jovyan/conda/envs/gcr/lib/python3.10/site-packages/torchbiggraph/train_cpu.py:304: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  ).storage()\n",
      "/home/jovyan/conda/envs/gcr/lib/python3.10/site-packages/torchbiggraph/train_cpu.py:821: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  self.embedding_storage_freelist[entity].add(embs.storage())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Embedding Complete]\n",
      "[Embeddig result saved at /home/jovyan/gcr/alo//.train_artifacts/output/graph/RESULT]\n",
      "\u001b[92m[2023-11-09 06:48:23,631][ASSET][INFO][train_pipeline][graph]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/gcr/alo//.train_artifacts/models/graph/\u001b[0m\n",
      "In __del__: pbg deleted\n",
      "\u001b[94m[2023-11-09 06:48:23,681][ASSET][INFO][train_pipeline][graph]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-09 06:48:23\n",
      "- current step      : graph\n",
      "- save config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:48:23,683][PROCESS][INFO]: ==================== Finish pipeline: train_pipeline / step: graph\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>is_married</th>\n",
       "      <th>EMB_00</th>\n",
       "      <th>EMB_01</th>\n",
       "      <th>EMB_02</th>\n",
       "      <th>EMB_03</th>\n",
       "      <th>EMB_04</th>\n",
       "      <th>EMB_05</th>\n",
       "      <th>EMB_06</th>\n",
       "      <th>EMB_07</th>\n",
       "      <th>...</th>\n",
       "      <th>EMB_54</th>\n",
       "      <th>EMB_55</th>\n",
       "      <th>EMB_56</th>\n",
       "      <th>EMB_57</th>\n",
       "      <th>EMB_58</th>\n",
       "      <th>EMB_59</th>\n",
       "      <th>EMB_60</th>\n",
       "      <th>EMB_61</th>\n",
       "      <th>EMB_62</th>\n",
       "      <th>EMB_63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jasmine_Young</td>\n",
       "      <td>False</td>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.012486</td>\n",
       "      <td>-0.006015</td>\n",
       "      <td>-0.002386</td>\n",
       "      <td>0.011126</td>\n",
       "      <td>-0.008311</td>\n",
       "      <td>0.004959</td>\n",
       "      <td>-0.006470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009567</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>-0.017530</td>\n",
       "      <td>0.010955</td>\n",
       "      <td>-0.009202</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>-0.011175</td>\n",
       "      <td>-0.015945</td>\n",
       "      <td>-0.005596</td>\n",
       "      <td>0.019304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jeffery_Robinson</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.004965</td>\n",
       "      <td>0.002876</td>\n",
       "      <td>0.008636</td>\n",
       "      <td>-0.010439</td>\n",
       "      <td>0.023527</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>-0.000218</td>\n",
       "      <td>0.007283</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001800</td>\n",
       "      <td>-0.004214</td>\n",
       "      <td>-0.002111</td>\n",
       "      <td>-0.006512</td>\n",
       "      <td>0.012473</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.015984</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.017025</td>\n",
       "      <td>-0.015097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Steven_Sullivan</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.007307</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>-0.014262</td>\n",
       "      <td>-0.004650</td>\n",
       "      <td>0.007345</td>\n",
       "      <td>-0.003880</td>\n",
       "      <td>-0.013454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005106</td>\n",
       "      <td>-0.012092</td>\n",
       "      <td>0.011724</td>\n",
       "      <td>-0.003504</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>-0.021452</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>-0.016730</td>\n",
       "      <td>-0.003460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jay_Williams</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.004796</td>\n",
       "      <td>-0.011855</td>\n",
       "      <td>-0.000744</td>\n",
       "      <td>-0.028423</td>\n",
       "      <td>-0.003113</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>-0.000301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>-0.003301</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>0.016012</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.021466</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.017054</td>\n",
       "      <td>0.013091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Benjamin_Beck</td>\n",
       "      <td>True</td>\n",
       "      <td>0.008599</td>\n",
       "      <td>0.006184</td>\n",
       "      <td>-0.008778</td>\n",
       "      <td>0.013065</td>\n",
       "      <td>-0.001219</td>\n",
       "      <td>0.003489</td>\n",
       "      <td>-0.002191</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019881</td>\n",
       "      <td>0.011763</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.008695</td>\n",
       "      <td>0.006855</td>\n",
       "      <td>-0.008508</td>\n",
       "      <td>-0.016589</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>-0.003252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gregory_Gomez</td>\n",
       "      <td>False</td>\n",
       "      <td>0.012754</td>\n",
       "      <td>-0.018615</td>\n",
       "      <td>0.010239</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>-0.000405</td>\n",
       "      <td>-0.003414</td>\n",
       "      <td>0.008341</td>\n",
       "      <td>0.007998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>-0.004254</td>\n",
       "      <td>0.014648</td>\n",
       "      <td>-0.011084</td>\n",
       "      <td>-0.013841</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.008417</td>\n",
       "      <td>0.005887</td>\n",
       "      <td>0.011425</td>\n",
       "      <td>-0.015615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mary_Harris</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.016583</td>\n",
       "      <td>-0.007072</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>-0.000602</td>\n",
       "      <td>0.011575</td>\n",
       "      <td>-0.004723</td>\n",
       "      <td>-0.001661</td>\n",
       "      <td>-0.001516</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004399</td>\n",
       "      <td>0.004914</td>\n",
       "      <td>-0.020739</td>\n",
       "      <td>-0.009642</td>\n",
       "      <td>-0.006034</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>-0.001273</td>\n",
       "      <td>0.003149</td>\n",
       "      <td>-0.009247</td>\n",
       "      <td>-0.009686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jimmy_Smith</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.002064</td>\n",
       "      <td>-0.012578</td>\n",
       "      <td>-0.003306</td>\n",
       "      <td>-0.023773</td>\n",
       "      <td>-0.003994</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>-0.001919</td>\n",
       "      <td>-0.003972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.007958</td>\n",
       "      <td>0.028603</td>\n",
       "      <td>0.004694</td>\n",
       "      <td>-0.002030</td>\n",
       "      <td>0.009108</td>\n",
       "      <td>0.005748</td>\n",
       "      <td>0.025328</td>\n",
       "      <td>0.014571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kenneth_Rubio</td>\n",
       "      <td>True</td>\n",
       "      <td>0.004767</td>\n",
       "      <td>-0.001059</td>\n",
       "      <td>0.009404</td>\n",
       "      <td>0.004373</td>\n",
       "      <td>0.014389</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.014582</td>\n",
       "      <td>-0.001605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007579</td>\n",
       "      <td>-0.002478</td>\n",
       "      <td>0.005899</td>\n",
       "      <td>-0.006245</td>\n",
       "      <td>-0.014657</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>-0.008563</td>\n",
       "      <td>-0.013228</td>\n",
       "      <td>-0.003193</td>\n",
       "      <td>0.009449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jordan_Simmons</td>\n",
       "      <td>False</td>\n",
       "      <td>0.012619</td>\n",
       "      <td>-0.007292</td>\n",
       "      <td>-0.009820</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>-0.005888</td>\n",
       "      <td>-0.017760</td>\n",
       "      <td>-0.003946</td>\n",
       "      <td>0.009210</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002693</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>-0.015153</td>\n",
       "      <td>-0.003669</td>\n",
       "      <td>0.009446</td>\n",
       "      <td>0.002774</td>\n",
       "      <td>0.004930</td>\n",
       "      <td>0.012031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               name is_married    EMB_00    EMB_01    EMB_02    EMB_03  \\\n",
       "0     Jasmine_Young      False  0.004884  0.012486 -0.006015 -0.002386   \n",
       "1  Jeffery_Robinson       True -0.004965  0.002876  0.008636 -0.010439   \n",
       "2   Steven_Sullivan      False -0.007307 -0.001668  0.002815 -0.014262   \n",
       "3      Jay_Williams      False -0.004796 -0.011855 -0.000744 -0.028423   \n",
       "4     Benjamin_Beck       True  0.008599  0.006184 -0.008778  0.013065   \n",
       "5     Gregory_Gomez      False  0.012754 -0.018615  0.010239  0.001928   \n",
       "6       Mary_Harris       True -0.016583 -0.007072  0.011364 -0.000602   \n",
       "7       Jimmy_Smith      False -0.002064 -0.012578 -0.003306 -0.023773   \n",
       "8     Kenneth_Rubio       True  0.004767 -0.001059  0.009404  0.004373   \n",
       "9    Jordan_Simmons      False  0.012619 -0.007292 -0.009820  0.000620   \n",
       "\n",
       "     EMB_04    EMB_05    EMB_06    EMB_07  ...    EMB_54    EMB_55    EMB_56  \\\n",
       "0  0.011126 -0.008311  0.004959 -0.006470  ...  0.009567  0.002214 -0.017530   \n",
       "1  0.023527 -0.000226 -0.000218  0.007283  ... -0.001800 -0.004214 -0.002111   \n",
       "2 -0.004650  0.007345 -0.003880 -0.013454  ...  0.005106 -0.012092  0.011724   \n",
       "3 -0.003113 -0.000233  0.004138 -0.000301  ...  0.002899 -0.003301  0.007938   \n",
       "4 -0.001219  0.003489 -0.002191  0.004630  ... -0.019881  0.011763  0.002243   \n",
       "5 -0.000405 -0.003414  0.008341  0.007998  ...  0.002808 -0.004254  0.014648   \n",
       "6  0.011575 -0.004723 -0.001661 -0.001516  ... -0.004399  0.004914 -0.020739   \n",
       "7 -0.003994  0.005666 -0.001919 -0.003972  ...  0.001486  0.004762  0.007958   \n",
       "8  0.014389  0.011747  0.014582 -0.001605  ...  0.007579 -0.002478  0.005899   \n",
       "9 -0.005888 -0.017760 -0.003946  0.009210  ... -0.002693  0.002364  0.010497   \n",
       "\n",
       "     EMB_57    EMB_58    EMB_59    EMB_60    EMB_61    EMB_62    EMB_63  \n",
       "0  0.010955 -0.009202  0.002822 -0.011175 -0.015945 -0.005596  0.019304  \n",
       "1 -0.006512  0.012473  0.000300  0.015984  0.003432  0.017025 -0.015097  \n",
       "2 -0.003504  0.002250 -0.021452  0.004200  0.000389 -0.016730 -0.003460  \n",
       "3  0.016012  0.001566  0.002212  0.021466  0.000897  0.017054  0.013091  \n",
       "4  0.000482  0.008695  0.006855 -0.008508 -0.016589  0.000847 -0.003252  \n",
       "5 -0.011084 -0.013841  0.000395  0.008417  0.005887  0.011425 -0.015615  \n",
       "6 -0.009642 -0.006034  0.001584 -0.001273  0.003149 -0.009247 -0.009686  \n",
       "7  0.028603  0.004694 -0.002030  0.009108  0.005748  0.025328  0.014571  \n",
       "8 -0.006245 -0.014657  0.011261 -0.008563 -0.013228 -0.003193  0.009449  \n",
       "9  0.000895 -0.015153 -0.003669  0.009446  0.002774  0.004930  0.012031  \n",
       "\n",
       "[10 rows x 66 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# asset 실행\n",
    "graph_asset_structure=run(step, pipeline, asset_structure)\n",
    "\n",
    "# graph asset의 결과 dataframe은 graph_asset_structure.data['dataframe']으로 확인할 수 있습니다. \n",
    "graph_asset_structure.data['dataframe'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7698dd0-9153-46c0-97d8-6971ab8f3b2c",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "### 2. Preprocess asset \n",
    "##### Preprocess asset의 args수정 및 확인\n",
    "- 필요한경우 preprocess_args의 항목을 ***asset_structure.args[argument명]=value입력*** 을 통해 변경할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91e75b62-dd0c-441a-a8db-eb6d15a4345b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'handling_missing': 'interpolation',\n",
       " 'handling_encoding_y_column': 'is_married',\n",
       " 'handling_encoding_y': 'label',\n",
       " 'handling_scaling_x': 'none',\n",
       " 'load_train_preprocess': False}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GCR asset 순서에 따라 step 순서를 입력합니다. (input(0) - graph(1) - preprocess(2) - sampling(3) - train(4))\n",
    "step = 2 \n",
    "asset_structure = copy.deepcopy(graph_asset_structure)\n",
    "asset_structure.args = alo.get_args(pipeline, step)\n",
    "\n",
    "# 아래 주석을 풀어 preprocess asset argument를 원하는 값으로 수정합니다. \n",
    "# asset_structure.args['handling_missing'] = dropna\n",
    "asset_structure.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2d78a8-0a32-4f54-aac7-bff907e2ae94",
   "metadata": {},
   "source": [
    "##### Preprocess asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a116e5ee-0eaa-4cad-9e8b-b7452f7068be",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[2023-11-09 06:48:26,059][ASSET][INFO][train_pipeline][preprocess]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/gcr/alo//.train_artifacts/models/preprocess/\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:48:26,061][ASSET][INFO][train_pipeline][preprocess]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-09 06:48:26\n",
      "- current step      : preprocess\n",
      "- asset branch.     : release-1.2\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['handling_missing', 'handling_encoding_y_column', 'handling_encoding_y', 'handling_scaling_x', 'load_train_preprocess'])\n",
      "- load config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns'])\n",
      "- load data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "is_married column : label Encoder saved : /home/jovyan/gcr/alo//.train_artifacts/models/preprocess/\n",
      "['EMB_00_nan', 'EMB_01_nan', 'EMB_02_nan', 'EMB_03_nan', 'EMB_04_nan', 'EMB_05_nan', 'EMB_06_nan', 'EMB_07_nan', 'EMB_08_nan', 'EMB_09_nan', 'EMB_10_nan', 'EMB_11_nan', 'EMB_12_nan', 'EMB_13_nan', 'EMB_14_nan', 'EMB_15_nan', 'EMB_16_nan', 'EMB_17_nan', 'EMB_18_nan', 'EMB_19_nan', 'EMB_20_nan', 'EMB_21_nan', 'EMB_22_nan', 'EMB_23_nan', 'EMB_24_nan', 'EMB_25_nan', 'EMB_26_nan', 'EMB_27_nan', 'EMB_28_nan', 'EMB_29_nan', 'EMB_30_nan', 'EMB_31_nan', 'EMB_32_nan', 'EMB_33_nan', 'EMB_34_nan', 'EMB_35_nan', 'EMB_36_nan', 'EMB_37_nan', 'EMB_38_nan', 'EMB_39_nan', 'EMB_40_nan', 'EMB_41_nan', 'EMB_42_nan', 'EMB_43_nan', 'EMB_44_nan', 'EMB_45_nan', 'EMB_46_nan', 'EMB_47_nan', 'EMB_48_nan', 'EMB_49_nan', 'EMB_50_nan', 'EMB_51_nan', 'EMB_52_nan', 'EMB_53_nan', 'EMB_54_nan', 'EMB_55_nan', 'EMB_56_nan', 'EMB_57_nan', 'EMB_58_nan', 'EMB_59_nan', 'EMB_60_nan', 'EMB_61_nan', 'EMB_62_nan', 'EMB_63_nan'] is_married_encoded_nan\n",
      "\u001b[94m[2023-11-09 06:48:26,082][ASSET][INFO][train_pipeline][preprocess]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-09 06:48:26\n",
      "- current step      : preprocess\n",
      "- save config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:48:26,084][PROCESS][INFO]: ==================== Finish pipeline: train_pipeline / step: preprocess\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMB_00</th>\n",
       "      <th>EMB_01</th>\n",
       "      <th>EMB_02</th>\n",
       "      <th>EMB_03</th>\n",
       "      <th>EMB_04</th>\n",
       "      <th>EMB_05</th>\n",
       "      <th>EMB_06</th>\n",
       "      <th>EMB_07</th>\n",
       "      <th>EMB_08</th>\n",
       "      <th>EMB_09</th>\n",
       "      <th>...</th>\n",
       "      <th>EMB_55_nan</th>\n",
       "      <th>EMB_56_nan</th>\n",
       "      <th>EMB_57_nan</th>\n",
       "      <th>EMB_58_nan</th>\n",
       "      <th>EMB_59_nan</th>\n",
       "      <th>EMB_60_nan</th>\n",
       "      <th>EMB_61_nan</th>\n",
       "      <th>EMB_62_nan</th>\n",
       "      <th>EMB_63_nan</th>\n",
       "      <th>is_married_encoded_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.012486</td>\n",
       "      <td>-0.006015</td>\n",
       "      <td>-0.002386</td>\n",
       "      <td>0.011126</td>\n",
       "      <td>-0.008311</td>\n",
       "      <td>0.004959</td>\n",
       "      <td>-0.006470</td>\n",
       "      <td>-0.012019</td>\n",
       "      <td>-0.014076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>-0.017530</td>\n",
       "      <td>0.010955</td>\n",
       "      <td>-0.009202</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>-0.011175</td>\n",
       "      <td>-0.015945</td>\n",
       "      <td>-0.005596</td>\n",
       "      <td>0.019304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.004965</td>\n",
       "      <td>0.002876</td>\n",
       "      <td>0.008636</td>\n",
       "      <td>-0.010439</td>\n",
       "      <td>0.023527</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>-0.000218</td>\n",
       "      <td>0.007283</td>\n",
       "      <td>-0.001113</td>\n",
       "      <td>-0.007204</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004214</td>\n",
       "      <td>-0.002111</td>\n",
       "      <td>-0.006512</td>\n",
       "      <td>0.012473</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.015984</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.017025</td>\n",
       "      <td>-0.015097</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.007307</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>-0.014262</td>\n",
       "      <td>-0.004650</td>\n",
       "      <td>0.007345</td>\n",
       "      <td>-0.003880</td>\n",
       "      <td>-0.013454</td>\n",
       "      <td>0.005971</td>\n",
       "      <td>0.014378</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012092</td>\n",
       "      <td>0.011724</td>\n",
       "      <td>-0.003504</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>-0.021452</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>-0.016730</td>\n",
       "      <td>-0.003460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.004796</td>\n",
       "      <td>-0.011855</td>\n",
       "      <td>-0.000744</td>\n",
       "      <td>-0.028423</td>\n",
       "      <td>-0.003113</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>-0.000301</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.010540</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003301</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>0.016012</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.021466</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.017054</td>\n",
       "      <td>0.013091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008599</td>\n",
       "      <td>0.006184</td>\n",
       "      <td>-0.008778</td>\n",
       "      <td>0.013065</td>\n",
       "      <td>-0.001219</td>\n",
       "      <td>0.003489</td>\n",
       "      <td>-0.002191</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>-0.007333</td>\n",
       "      <td>-0.009585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011763</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.008695</td>\n",
       "      <td>0.006855</td>\n",
       "      <td>-0.008508</td>\n",
       "      <td>-0.016589</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>-0.003252</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.012754</td>\n",
       "      <td>-0.018615</td>\n",
       "      <td>0.010239</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>-0.000405</td>\n",
       "      <td>-0.003414</td>\n",
       "      <td>0.008341</td>\n",
       "      <td>0.007998</td>\n",
       "      <td>-0.013744</td>\n",
       "      <td>-0.005918</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004254</td>\n",
       "      <td>0.014648</td>\n",
       "      <td>-0.011084</td>\n",
       "      <td>-0.013841</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.008417</td>\n",
       "      <td>0.005887</td>\n",
       "      <td>0.011425</td>\n",
       "      <td>-0.015615</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.016583</td>\n",
       "      <td>-0.007072</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>-0.000602</td>\n",
       "      <td>0.011575</td>\n",
       "      <td>-0.004723</td>\n",
       "      <td>-0.001661</td>\n",
       "      <td>-0.001516</td>\n",
       "      <td>0.012096</td>\n",
       "      <td>-0.006577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004914</td>\n",
       "      <td>-0.020739</td>\n",
       "      <td>-0.009642</td>\n",
       "      <td>-0.006034</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>-0.001273</td>\n",
       "      <td>0.003149</td>\n",
       "      <td>-0.009247</td>\n",
       "      <td>-0.009686</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.002064</td>\n",
       "      <td>-0.012578</td>\n",
       "      <td>-0.003306</td>\n",
       "      <td>-0.023773</td>\n",
       "      <td>-0.003994</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>-0.001919</td>\n",
       "      <td>-0.003972</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>0.014876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.007958</td>\n",
       "      <td>0.028603</td>\n",
       "      <td>0.004694</td>\n",
       "      <td>-0.002030</td>\n",
       "      <td>0.009108</td>\n",
       "      <td>0.005748</td>\n",
       "      <td>0.025328</td>\n",
       "      <td>0.014571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.004767</td>\n",
       "      <td>-0.001059</td>\n",
       "      <td>0.009404</td>\n",
       "      <td>0.004373</td>\n",
       "      <td>0.014389</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.014582</td>\n",
       "      <td>-0.001605</td>\n",
       "      <td>0.024003</td>\n",
       "      <td>-0.008056</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002478</td>\n",
       "      <td>0.005899</td>\n",
       "      <td>-0.006245</td>\n",
       "      <td>-0.014657</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>-0.008563</td>\n",
       "      <td>-0.013228</td>\n",
       "      <td>-0.003193</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.012619</td>\n",
       "      <td>-0.007292</td>\n",
       "      <td>-0.009820</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>-0.005888</td>\n",
       "      <td>-0.017760</td>\n",
       "      <td>-0.003946</td>\n",
       "      <td>0.009210</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.015868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>-0.015153</td>\n",
       "      <td>-0.003669</td>\n",
       "      <td>0.009446</td>\n",
       "      <td>0.002774</td>\n",
       "      <td>0.004930</td>\n",
       "      <td>0.012031</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     EMB_00    EMB_01    EMB_02    EMB_03    EMB_04    EMB_05    EMB_06  \\\n",
       "0  0.004884  0.012486 -0.006015 -0.002386  0.011126 -0.008311  0.004959   \n",
       "1 -0.004965  0.002876  0.008636 -0.010439  0.023527 -0.000226 -0.000218   \n",
       "2 -0.007307 -0.001668  0.002815 -0.014262 -0.004650  0.007345 -0.003880   \n",
       "3 -0.004796 -0.011855 -0.000744 -0.028423 -0.003113 -0.000233  0.004138   \n",
       "4  0.008599  0.006184 -0.008778  0.013065 -0.001219  0.003489 -0.002191   \n",
       "5  0.012754 -0.018615  0.010239  0.001928 -0.000405 -0.003414  0.008341   \n",
       "6 -0.016583 -0.007072  0.011364 -0.000602  0.011575 -0.004723 -0.001661   \n",
       "7 -0.002064 -0.012578 -0.003306 -0.023773 -0.003994  0.005666 -0.001919   \n",
       "8  0.004767 -0.001059  0.009404  0.004373  0.014389  0.011747  0.014582   \n",
       "9  0.012619 -0.007292 -0.009820  0.000620 -0.005888 -0.017760 -0.003946   \n",
       "\n",
       "     EMB_07    EMB_08    EMB_09  ...  EMB_55_nan  EMB_56_nan  EMB_57_nan  \\\n",
       "0 -0.006470 -0.012019 -0.014076  ...    0.002214   -0.017530    0.010955   \n",
       "1  0.007283 -0.001113 -0.007204  ...   -0.004214   -0.002111   -0.006512   \n",
       "2 -0.013454  0.005971  0.014378  ...   -0.012092    0.011724   -0.003504   \n",
       "3 -0.000301  0.000790  0.010540  ...   -0.003301    0.007938    0.016012   \n",
       "4  0.004630 -0.007333 -0.009585  ...    0.011763    0.002243    0.000482   \n",
       "5  0.007998 -0.013744 -0.005918  ...   -0.004254    0.014648   -0.011084   \n",
       "6 -0.001516  0.012096 -0.006577  ...    0.004914   -0.020739   -0.009642   \n",
       "7 -0.003972  0.004233  0.014876  ...    0.004762    0.007958    0.028603   \n",
       "8 -0.001605  0.024003 -0.008056  ...   -0.002478    0.005899   -0.006245   \n",
       "9  0.009210  0.000535  0.015868  ...    0.002364    0.010497    0.000895   \n",
       "\n",
       "   EMB_58_nan  EMB_59_nan  EMB_60_nan  EMB_61_nan  EMB_62_nan  EMB_63_nan  \\\n",
       "0   -0.009202    0.002822   -0.011175   -0.015945   -0.005596    0.019304   \n",
       "1    0.012473    0.000300    0.015984    0.003432    0.017025   -0.015097   \n",
       "2    0.002250   -0.021452    0.004200    0.000389   -0.016730   -0.003460   \n",
       "3    0.001566    0.002212    0.021466    0.000897    0.017054    0.013091   \n",
       "4    0.008695    0.006855   -0.008508   -0.016589    0.000847   -0.003252   \n",
       "5   -0.013841    0.000395    0.008417    0.005887    0.011425   -0.015615   \n",
       "6   -0.006034    0.001584   -0.001273    0.003149   -0.009247   -0.009686   \n",
       "7    0.004694   -0.002030    0.009108    0.005748    0.025328    0.014571   \n",
       "8   -0.014657    0.011261   -0.008563   -0.013228   -0.003193    0.009449   \n",
       "9   -0.015153   -0.003669    0.009446    0.002774    0.004930    0.012031   \n",
       "\n",
       "   is_married_encoded_nan  \n",
       "0                       0  \n",
       "1                       1  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       1  \n",
       "5                       0  \n",
       "6                       1  \n",
       "7                       0  \n",
       "8                       1  \n",
       "9                       0  \n",
       "\n",
       "[10 rows x 131 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# asset 실행\n",
    "preprocess_asset_structure=run(step, pipeline, asset_structure)\n",
    "\n",
    "# preprocess asset의 결과 dataframe은 preprocess_asset_structure.data['dataframe']으로 확인할 수 있습니다.  \n",
    "preprocess_asset_structure.data['dataframe'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd463df-8ac2-4eeb-a020-49f89a05c5a1",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "### 3. Sampling asset \n",
    "##### Sampling asset의 args수정 및 확인\n",
    "- 필요한경우 Sampling_args의 항목을 ***asset_structure.args[argument명]=value입력*** 을 통해 변경할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a20b2f60-8fb3-4115-9006-8bee0b3c5ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sampling_type': 'none',\n",
       " 'sampling_method': 'negative',\n",
       " 'label_sampling': True,\n",
       " 'ignore_label_class': None,\n",
       " 'negative_target_class': None,\n",
       " 'label_sampling_num_type': None,\n",
       " 'label_sampling_num': {1: 1, 0: 25},\n",
       " 'sampling_groupkey_columns': None,\n",
       " 'sampling_num_type': None,\n",
       " 'sampling_num': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GCR asset 순서에 따라 step 순서를 입력합니다. (input(0) - graph(1) - preprocess(2) - sampling(3) - train(4))\n",
    "step = 3 \n",
    "asset_structure = copy.deepcopy(preprocess_asset_structure)\n",
    "asset_structure.args = alo.get_args(pipeline, step)\n",
    "\n",
    "# 아래 주석을 풀어 sampling asset argument를 원하는 값으로 수정합니다. \n",
    "# asset_structure.args['sampling_type'] = 'under'\n",
    "asset_structure.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4230191c-ec22-4e85-9a18-82817a90e2fb",
   "metadata": {},
   "source": [
    "##### Sampling asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "025f4f8c-f430-4c28-b8e0-e27e7fe1a0db",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda/envs/gcr/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[2023-11-09 06:48:31,630][ASSET][INFO][train_pipeline][sampling]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-09 06:48:31\n",
      "- current step      : sampling\n",
      "- asset branch.     : release-1.2\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['sampling_type', 'sampling_method', 'label_sampling', 'ignore_label_class', 'negative_target_class', 'label_sampling_num_type', 'label_sampling_num', 'sampling_groupkey_columns', 'sampling_num_type', 'sampling_num'])\n",
      "- load config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess'])\n",
      "- load data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[92m[2023-11-09 06:48:31,653][ASSET][INFO][train_pipeline][sampling]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/gcr/alo//.train_artifacts/models/sampling/\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:48:31,655][ASSET][INFO][train_pipeline][sampling]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-09 06:48:31\n",
      "- current step      : sampling\n",
      "- save config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess', 'sampling_type'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:48:31,658][PROCESS][INFO]: ==================== Finish pipeline: train_pipeline / step: sampling\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMB_00</th>\n",
       "      <th>EMB_01</th>\n",
       "      <th>EMB_02</th>\n",
       "      <th>EMB_03</th>\n",
       "      <th>EMB_04</th>\n",
       "      <th>EMB_05</th>\n",
       "      <th>EMB_06</th>\n",
       "      <th>EMB_07</th>\n",
       "      <th>EMB_08</th>\n",
       "      <th>EMB_09</th>\n",
       "      <th>...</th>\n",
       "      <th>EMB_55_nan</th>\n",
       "      <th>EMB_56_nan</th>\n",
       "      <th>EMB_57_nan</th>\n",
       "      <th>EMB_58_nan</th>\n",
       "      <th>EMB_59_nan</th>\n",
       "      <th>EMB_60_nan</th>\n",
       "      <th>EMB_61_nan</th>\n",
       "      <th>EMB_62_nan</th>\n",
       "      <th>EMB_63_nan</th>\n",
       "      <th>is_married_encoded_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004884</td>\n",
       "      <td>0.012486</td>\n",
       "      <td>-0.006015</td>\n",
       "      <td>-0.002386</td>\n",
       "      <td>0.011126</td>\n",
       "      <td>-0.008311</td>\n",
       "      <td>0.004959</td>\n",
       "      <td>-0.006470</td>\n",
       "      <td>-0.012019</td>\n",
       "      <td>-0.014076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>-0.017530</td>\n",
       "      <td>0.010955</td>\n",
       "      <td>-0.009202</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>-0.011175</td>\n",
       "      <td>-0.015945</td>\n",
       "      <td>-0.005596</td>\n",
       "      <td>0.019304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.004965</td>\n",
       "      <td>0.002876</td>\n",
       "      <td>0.008636</td>\n",
       "      <td>-0.010439</td>\n",
       "      <td>0.023527</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>-0.000218</td>\n",
       "      <td>0.007283</td>\n",
       "      <td>-0.001113</td>\n",
       "      <td>-0.007204</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004214</td>\n",
       "      <td>-0.002111</td>\n",
       "      <td>-0.006512</td>\n",
       "      <td>0.012473</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.015984</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.017025</td>\n",
       "      <td>-0.015097</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.007307</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>-0.014262</td>\n",
       "      <td>-0.004650</td>\n",
       "      <td>0.007345</td>\n",
       "      <td>-0.003880</td>\n",
       "      <td>-0.013454</td>\n",
       "      <td>0.005971</td>\n",
       "      <td>0.014378</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012092</td>\n",
       "      <td>0.011724</td>\n",
       "      <td>-0.003504</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>-0.021452</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>-0.016730</td>\n",
       "      <td>-0.003460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.004796</td>\n",
       "      <td>-0.011855</td>\n",
       "      <td>-0.000744</td>\n",
       "      <td>-0.028423</td>\n",
       "      <td>-0.003113</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>-0.000301</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.010540</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003301</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>0.016012</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.021466</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.017054</td>\n",
       "      <td>0.013091</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008599</td>\n",
       "      <td>0.006184</td>\n",
       "      <td>-0.008778</td>\n",
       "      <td>0.013065</td>\n",
       "      <td>-0.001219</td>\n",
       "      <td>0.003489</td>\n",
       "      <td>-0.002191</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>-0.007333</td>\n",
       "      <td>-0.009585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011763</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.008695</td>\n",
       "      <td>0.006855</td>\n",
       "      <td>-0.008508</td>\n",
       "      <td>-0.016589</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>-0.003252</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.012754</td>\n",
       "      <td>-0.018615</td>\n",
       "      <td>0.010239</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>-0.000405</td>\n",
       "      <td>-0.003414</td>\n",
       "      <td>0.008341</td>\n",
       "      <td>0.007998</td>\n",
       "      <td>-0.013744</td>\n",
       "      <td>-0.005918</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004254</td>\n",
       "      <td>0.014648</td>\n",
       "      <td>-0.011084</td>\n",
       "      <td>-0.013841</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.008417</td>\n",
       "      <td>0.005887</td>\n",
       "      <td>0.011425</td>\n",
       "      <td>-0.015615</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.016583</td>\n",
       "      <td>-0.007072</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>-0.000602</td>\n",
       "      <td>0.011575</td>\n",
       "      <td>-0.004723</td>\n",
       "      <td>-0.001661</td>\n",
       "      <td>-0.001516</td>\n",
       "      <td>0.012096</td>\n",
       "      <td>-0.006577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004914</td>\n",
       "      <td>-0.020739</td>\n",
       "      <td>-0.009642</td>\n",
       "      <td>-0.006034</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>-0.001273</td>\n",
       "      <td>0.003149</td>\n",
       "      <td>-0.009247</td>\n",
       "      <td>-0.009686</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.002064</td>\n",
       "      <td>-0.012578</td>\n",
       "      <td>-0.003306</td>\n",
       "      <td>-0.023773</td>\n",
       "      <td>-0.003994</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>-0.001919</td>\n",
       "      <td>-0.003972</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>0.014876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.007958</td>\n",
       "      <td>0.028603</td>\n",
       "      <td>0.004694</td>\n",
       "      <td>-0.002030</td>\n",
       "      <td>0.009108</td>\n",
       "      <td>0.005748</td>\n",
       "      <td>0.025328</td>\n",
       "      <td>0.014571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.004767</td>\n",
       "      <td>-0.001059</td>\n",
       "      <td>0.009404</td>\n",
       "      <td>0.004373</td>\n",
       "      <td>0.014389</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.014582</td>\n",
       "      <td>-0.001605</td>\n",
       "      <td>0.024003</td>\n",
       "      <td>-0.008056</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002478</td>\n",
       "      <td>0.005899</td>\n",
       "      <td>-0.006245</td>\n",
       "      <td>-0.014657</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>-0.008563</td>\n",
       "      <td>-0.013228</td>\n",
       "      <td>-0.003193</td>\n",
       "      <td>0.009449</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.012619</td>\n",
       "      <td>-0.007292</td>\n",
       "      <td>-0.009820</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>-0.005888</td>\n",
       "      <td>-0.017760</td>\n",
       "      <td>-0.003946</td>\n",
       "      <td>0.009210</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.015868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>-0.015153</td>\n",
       "      <td>-0.003669</td>\n",
       "      <td>0.009446</td>\n",
       "      <td>0.002774</td>\n",
       "      <td>0.004930</td>\n",
       "      <td>0.012031</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     EMB_00    EMB_01    EMB_02    EMB_03    EMB_04    EMB_05    EMB_06  \\\n",
       "0  0.004884  0.012486 -0.006015 -0.002386  0.011126 -0.008311  0.004959   \n",
       "1 -0.004965  0.002876  0.008636 -0.010439  0.023527 -0.000226 -0.000218   \n",
       "2 -0.007307 -0.001668  0.002815 -0.014262 -0.004650  0.007345 -0.003880   \n",
       "3 -0.004796 -0.011855 -0.000744 -0.028423 -0.003113 -0.000233  0.004138   \n",
       "4  0.008599  0.006184 -0.008778  0.013065 -0.001219  0.003489 -0.002191   \n",
       "5  0.012754 -0.018615  0.010239  0.001928 -0.000405 -0.003414  0.008341   \n",
       "6 -0.016583 -0.007072  0.011364 -0.000602  0.011575 -0.004723 -0.001661   \n",
       "7 -0.002064 -0.012578 -0.003306 -0.023773 -0.003994  0.005666 -0.001919   \n",
       "8  0.004767 -0.001059  0.009404  0.004373  0.014389  0.011747  0.014582   \n",
       "9  0.012619 -0.007292 -0.009820  0.000620 -0.005888 -0.017760 -0.003946   \n",
       "\n",
       "     EMB_07    EMB_08    EMB_09  ...  EMB_55_nan  EMB_56_nan  EMB_57_nan  \\\n",
       "0 -0.006470 -0.012019 -0.014076  ...    0.002214   -0.017530    0.010955   \n",
       "1  0.007283 -0.001113 -0.007204  ...   -0.004214   -0.002111   -0.006512   \n",
       "2 -0.013454  0.005971  0.014378  ...   -0.012092    0.011724   -0.003504   \n",
       "3 -0.000301  0.000790  0.010540  ...   -0.003301    0.007938    0.016012   \n",
       "4  0.004630 -0.007333 -0.009585  ...    0.011763    0.002243    0.000482   \n",
       "5  0.007998 -0.013744 -0.005918  ...   -0.004254    0.014648   -0.011084   \n",
       "6 -0.001516  0.012096 -0.006577  ...    0.004914   -0.020739   -0.009642   \n",
       "7 -0.003972  0.004233  0.014876  ...    0.004762    0.007958    0.028603   \n",
       "8 -0.001605  0.024003 -0.008056  ...   -0.002478    0.005899   -0.006245   \n",
       "9  0.009210  0.000535  0.015868  ...    0.002364    0.010497    0.000895   \n",
       "\n",
       "   EMB_58_nan  EMB_59_nan  EMB_60_nan  EMB_61_nan  EMB_62_nan  EMB_63_nan  \\\n",
       "0   -0.009202    0.002822   -0.011175   -0.015945   -0.005596    0.019304   \n",
       "1    0.012473    0.000300    0.015984    0.003432    0.017025   -0.015097   \n",
       "2    0.002250   -0.021452    0.004200    0.000389   -0.016730   -0.003460   \n",
       "3    0.001566    0.002212    0.021466    0.000897    0.017054    0.013091   \n",
       "4    0.008695    0.006855   -0.008508   -0.016589    0.000847   -0.003252   \n",
       "5   -0.013841    0.000395    0.008417    0.005887    0.011425   -0.015615   \n",
       "6   -0.006034    0.001584   -0.001273    0.003149   -0.009247   -0.009686   \n",
       "7    0.004694   -0.002030    0.009108    0.005748    0.025328    0.014571   \n",
       "8   -0.014657    0.011261   -0.008563   -0.013228   -0.003193    0.009449   \n",
       "9   -0.015153   -0.003669    0.009446    0.002774    0.004930    0.012031   \n",
       "\n",
       "   is_married_encoded_nan  \n",
       "0                       0  \n",
       "1                       1  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       1  \n",
       "5                       0  \n",
       "6                       1  \n",
       "7                       0  \n",
       "8                       1  \n",
       "9                       0  \n",
       "\n",
       "[10 rows x 131 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# asset 실행\n",
    "sampling_asset_structure=run(step, pipeline, asset_structure)\n",
    "\n",
    "# sampling asset의 결과 dataframe은 sampling_asset_structure.data['dataframe']으로 확인할 수 있습니다.\n",
    "sampling_asset_structure.data['dataframe'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b6a3a7-2204-42b5-8cc8-a5b5f740f457",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "### 4. Train asset \n",
    "##### Train asset의 args수정 및 확인\n",
    "- 필요한경우 train_args의 항목을 ***asset_structure.args[argument명]=value입력*** 을 통해 변경할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39f0149f-bfb4-4223-835a-769fd57594bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_type': 'classification',\n",
       " 'data_split_method': 'cross_validate',\n",
       " 'evaluation_metric': 'accuracy',\n",
       " 'model_list': ['lgb', 'rf', 'cb'],\n",
       " 'num_hpo': 3,\n",
       " 'param_range': {'rf': {'max_depth': 6, 'n_estimators': [300, 500]},\n",
       "  'gbm': {'max_depth': [5, 7], 'n_estimators': [300, 500]},\n",
       "  'ngb': {'col_sample': [0.6, 0.8], 'n_estimators': [100, 300]},\n",
       "  'lgb': {'max_depth': [5, 9], 'n_estimators': [300, 500]},\n",
       "  'cb': {'max_depth': [5, 9], 'n_estimators': [100, 500]}},\n",
       " 'shap_ratio': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GCR asset 순서에 따라 step 순서를 입력합니다. (input(0) - graph(1) - preprocess(2) - sampling(3) - train(4))\n",
    "step = 4 \n",
    "asset_structure = copy.deepcopy(sampling_asset_structure)\n",
    "asset_structure.args = alo.get_args(pipeline, step)\n",
    "\n",
    "# 아래 주석을 풀어 train asset argument를 원하는 값으로 수정합니다.\n",
    "# asset_structure.args['num_hpo'] = 1\n",
    "asset_structure.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0c0b28-561d-4815-b4fc-f2078e1a0f59",
   "metadata": {},
   "source": [
    "##### Train asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c2a5dcd-b0b8-455d-8b68-3483238a5aae",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[2023-11-09 06:48:32,635][ASSET][INFO][train_pipeline][train]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/gcr/alo//.train_artifacts/models/train/\u001b[0m\n",
      "\u001b[92m[2023-11-09 06:48:32,639][ASSET][INFO][train_pipeline][train]: Successfully got << output path >> for saving your data into csv or jpg file: \n",
      " /home/jovyan/gcr/alo//.train_artifacts/output/train/ \n",
      " - [NOTE] The names of output file must be fixed as << output.csv, output.jpg >> \u001b[0m\n",
      "\u001b[94m[2023-11-09 06:48:32,642][ASSET][INFO][train_pipeline][train]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-09 06:48:32\n",
      "- current step      : train\n",
      "- asset branch.     : tcr_v1.1.1\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['model_type', 'data_split_method', 'evaluation_metric', 'model_list', 'num_hpo', 'param_range', 'shap_ratio'])\n",
      "- load config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess', 'sampling_type'])\n",
      "- load data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[92m[2023-11-09 06:48:32,644][ASSET][INFO][train_pipeline][train]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/gcr/alo//.train_artifacts/models/train/\u001b[0m\n",
      "\u001b[92m[2023-11-09 06:48:32,646][ASSET][INFO][train_pipeline][train]: Successfully got << output path >> for saving your data into csv or jpg file: \n",
      " /home/jovyan/gcr/alo//.train_artifacts/output/train/ \n",
      " - [NOTE] The names of output file must be fixed as << output.csv, output.jpg >> \u001b[0m\n",
      "\u001b[92m[2023-11-09 06:48:32,647][ASSET][INFO][train_pipeline][train]: Successfully got << report path >> for saving your << report.html >> file: \n",
      " /home/jovyan/gcr/alo//.train_artifacts/report/\u001b[0m\n",
      "해당 column 은 Training 과정에 사용되지 않습니다. (column_name: ['EMB_49', 'EMB_02', 'EMB_15', 'EMB_55', 'EMB_56', 'EMB_18', 'EMB_54', 'EMB_50', 'EMB_25', 'EMB_29', 'EMB_48', 'EMB_23', 'EMB_63', 'EMB_11', 'EMB_09', 'EMB_21', 'EMB_34', 'EMB_17', 'EMB_43', 'EMB_52', 'EMB_22', 'EMB_36', 'is_married_encoded', 'EMB_61', 'EMB_12', 'EMB_10', 'EMB_00', 'EMB_31', 'EMB_62', 'EMB_38', 'EMB_26', 'EMB_57', 'EMB_28', 'is_married_encoded_nan', 'EMB_05', 'EMB_20', 'EMB_07', 'EMB_46', 'EMB_44', 'EMB_39', 'EMB_60', 'EMB_40', 'is_married', 'EMB_24', 'EMB_58', 'EMB_37', 'EMB_51', 'EMB_35', 'EMB_13', 'EMB_42', 'EMB_04', 'EMB_06', 'EMB_14', 'EMB_16', 'EMB_19', 'EMB_53', 'EMB_30', 'EMB_45', 'EMB_01', 'EMB_27', 'EMB_41', 'EMB_03', 'EMB_08', 'EMB_59', 'EMB_32', 'EMB_47', 'EMB_33'])\n",
      "[INFO] 모델 학습을 시작합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 0th-fold RandomForestClassifier_set0 모델을 학습합니다.(1/36)\n",
      "[INFO] 1th-fold RandomForestClassifier_set0 모델을 학습합니다.(2/36)\n",
      "[INFO] 2th-fold RandomForestClassifier_set0 모델을 학습합니다.(3/36)\n",
      "[INFO] 3th-fold RandomForestClassifier_set0 모델을 학습합니다.(4/36)\n",
      "[INFO] 0th-fold RandomForestClassifier_set1 모델을 학습합니다.(5/36)\n",
      "[INFO] 1th-fold RandomForestClassifier_set1 모델을 학습합니다.(6/36)\n",
      "[INFO] 2th-fold RandomForestClassifier_set1 모델을 학습합니다.(7/36)\n",
      "[INFO] 3th-fold RandomForestClassifier_set1 모델을 학습합니다.(8/36)\n",
      "[INFO] 0th-fold RandomForestClassifier_set2 모델을 학습합니다.(9/36)\n",
      "[INFO] 1th-fold RandomForestClassifier_set2 모델을 학습합니다.(10/36)\n",
      "[INFO] 2th-fold RandomForestClassifier_set2 모델을 학습합니다.(11/36)\n",
      "[INFO] 3th-fold RandomForestClassifier_set2 모델을 학습합니다.(12/36)\n",
      "[INFO] 0th-fold LGBMClassifier_set0 모델을 학습합니다.(13/36)\n",
      "[INFO] 1th-fold LGBMClassifier_set0 모델을 학습합니다.(14/36)\n",
      "[INFO] 2th-fold LGBMClassifier_set0 모델을 학습합니다.(15/36)\n",
      "[INFO] 3th-fold LGBMClassifier_set0 모델을 학습합니다.(16/36)\n",
      "[INFO] 0th-fold LGBMClassifier_set1 모델을 학습합니다.(17/36)\n",
      "[INFO] 1th-fold LGBMClassifier_set1 모델을 학습합니다.(18/36)\n",
      "[INFO] 2th-fold LGBMClassifier_set1 모델을 학습합니다.(19/36)\n",
      "[INFO] 3th-fold LGBMClassifier_set1 모델을 학습합니다.(20/36)\n",
      "[INFO] 0th-fold LGBMClassifier_set2 모델을 학습합니다.(21/36)\n",
      "[INFO] 1th-fold LGBMClassifier_set2 모델을 학습합니다.(22/36)\n",
      "[INFO] 2th-fold LGBMClassifier_set2 모델을 학습합니다.(23/36)\n",
      "[INFO] 3th-fold LGBMClassifier_set2 모델을 학습합니다.(24/36)\n",
      "[INFO] 0th-fold CatBoostClassifier_set0 모델을 학습합니다.(25/36)\n",
      "[INFO] 1th-fold CatBoostClassifier_set0 모델을 학습합니다.(26/36)\n",
      "[INFO] 2th-fold CatBoostClassifier_set0 모델을 학습합니다.(27/36)\n",
      "[INFO] 3th-fold CatBoostClassifier_set0 모델을 학습합니다.(28/36)\n",
      "[INFO] 0th-fold CatBoostClassifier_set1 모델을 학습합니다.(29/36)\n",
      "[INFO] 1th-fold CatBoostClassifier_set1 모델을 학습합니다.(30/36)\n",
      "[INFO] 2th-fold CatBoostClassifier_set1 모델을 학습합니다.(31/36)\n",
      "[INFO] 3th-fold CatBoostClassifier_set1 모델을 학습합니다.(32/36)\n",
      "[INFO] 0th-fold CatBoostClassifier_set2 모델을 학습합니다.(33/36)\n",
      "[INFO] 1th-fold CatBoostClassifier_set2 모델을 학습합니다.(34/36)\n",
      "[INFO] 2th-fold CatBoostClassifier_set2 모델을 학습합니다.(35/36)\n",
      "[INFO] 3th-fold CatBoostClassifier_set2 모델을 학습합니다.(36/36)\n",
      "@scoring_classification func. - label list: @scoring_classification func. - label list: @scoring_classification func. - label list: @scoring_classification func. - label list: @scoring_classification func. - label list: @scoring_classification func. - label list: @scoring_classification func. - label list: @scoring_classification func. - label list: @scoring_classification func. - label list:         {0, 1} {0, 1}{0, 1}{0, 1}{0, 1}{0, 1}{0, 1}{0, 1}\n",
      "\n",
      "{0, 1}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[INFO] 평가 지표는 ( accuracy ) 를 사용합니다. \n",
      "모델 정보 로그를 저장합니다. (저장위치: /home/jovyan/gcr/alo//.train_artifacts/models/train/model_selection.json)\n",
      "\n",
      "Top 1 model file is saved: /home/jovyan/gcr/alo//.train_artifacts/models/train/best_model_top0.pkl\n",
      "[Score] accuracy: 0.7100\n",
      "[Hyper-parameters] n_estimators: 300, n_jobs: 1, random_state: 1234, max_depth: 6, \n",
      "\n",
      "Top 2 model file is saved: /home/jovyan/gcr/alo//.train_artifacts/models/train/best_model_top1.pkl\n",
      "[Score] accuracy: 0.7100\n",
      "[Hyper-parameters] n_estimators: 400, n_jobs: 1, random_state: 1234, max_depth: 6, \n",
      "\n",
      "Top 3 model file is saved: /home/jovyan/gcr/alo//.train_artifacts/models/train/best_model_top2.pkl\n",
      "[Score] accuracy: 0.7088\n",
      "[Hyper-parameters] n_estimators: 500, n_jobs: 1, random_state: 1234, max_depth: 6, \n",
      "\n",
      "Following model is the best: RandomForestClassifier_set0 / accuracy:0.7100\n",
      "\n",
      "================================================================================\n",
      "\n",
      "[INFO] Summary_plot for Train data 를 저장했습니다.\n",
      "\n",
      "ignore columns와 X로 지정한 데이터 프레임을 합치는 과정중에 에러가 발생했습니다. 확인 부탁드립니다.\n",
      "\u001b[94m[2023-11-09 06:50:11,697][ASSET][INFO][train_pipeline][train]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-09 06:50:11\n",
      "- current step      : train\n",
      "- save config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess', 'sampling_type', 'feature_dict'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:50:11,700][PROCESS][INFO]: ==================== Finish pipeline: train_pipeline / step: train\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMB_00_nan</th>\n",
       "      <th>EMB_01_nan</th>\n",
       "      <th>EMB_02_nan</th>\n",
       "      <th>EMB_03_nan</th>\n",
       "      <th>EMB_04_nan</th>\n",
       "      <th>EMB_05_nan</th>\n",
       "      <th>EMB_06_nan</th>\n",
       "      <th>EMB_07_nan</th>\n",
       "      <th>EMB_08_nan</th>\n",
       "      <th>EMB_09_nan</th>\n",
       "      <th>...</th>\n",
       "      <th>EMB_61_nan_shapley</th>\n",
       "      <th>EMB_62_nan_shapley</th>\n",
       "      <th>EMB_63_nan_shapley</th>\n",
       "      <th>is_married_encoded_nan</th>\n",
       "      <th>pred_is_married_encoded_nan</th>\n",
       "      <th>pred_is_married_encoded_nan_best0</th>\n",
       "      <th>pred_is_married_encoded_nan_best1</th>\n",
       "      <th>pred_is_married_encoded_nan_best2</th>\n",
       "      <th>prob_0</th>\n",
       "      <th>prob_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.003037</td>\n",
       "      <td>-0.007141</td>\n",
       "      <td>-0.011213</td>\n",
       "      <td>-0.009984</td>\n",
       "      <td>-0.017912</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>0.010962</td>\n",
       "      <td>-0.003464</td>\n",
       "      <td>0.029793</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>0.005541</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.730504</td>\n",
       "      <td>0.269496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020391</td>\n",
       "      <td>0.012623</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.006033</td>\n",
       "      <td>0.011504</td>\n",
       "      <td>-0.000077</td>\n",
       "      <td>-0.004077</td>\n",
       "      <td>-0.012035</td>\n",
       "      <td>-0.006936</td>\n",
       "      <td>-0.007154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>0.001441</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.691984</td>\n",
       "      <td>0.308016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.008391</td>\n",
       "      <td>0.006389</td>\n",
       "      <td>-0.005018</td>\n",
       "      <td>0.005226</td>\n",
       "      <td>-0.010767</td>\n",
       "      <td>-0.006289</td>\n",
       "      <td>-0.011314</td>\n",
       "      <td>0.005314</td>\n",
       "      <td>0.008374</td>\n",
       "      <td>0.012083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>0.003575</td>\n",
       "      <td>-0.002715</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.657182</td>\n",
       "      <td>0.342818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028635</td>\n",
       "      <td>0.005089</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.018450</td>\n",
       "      <td>0.015206</td>\n",
       "      <td>0.014947</td>\n",
       "      <td>0.007226</td>\n",
       "      <td>-0.000419</td>\n",
       "      <td>-0.004884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.003794</td>\n",
       "      <td>-0.000589</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.537598</td>\n",
       "      <td>0.462402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015572</td>\n",
       "      <td>-0.006919</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>0.003251</td>\n",
       "      <td>-0.006207</td>\n",
       "      <td>-0.009328</td>\n",
       "      <td>-0.008082</td>\n",
       "      <td>-0.020240</td>\n",
       "      <td>-0.018865</td>\n",
       "      <td>-0.005995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>-0.001818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.785848</td>\n",
       "      <td>0.214152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.012488</td>\n",
       "      <td>0.010970</td>\n",
       "      <td>0.011845</td>\n",
       "      <td>-0.003121</td>\n",
       "      <td>0.011537</td>\n",
       "      <td>0.009381</td>\n",
       "      <td>-0.006645</td>\n",
       "      <td>0.013332</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>-0.011121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>-0.016766</td>\n",
       "      <td>-0.005733</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.690500</td>\n",
       "      <td>0.309500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.015535</td>\n",
       "      <td>0.011653</td>\n",
       "      <td>0.010402</td>\n",
       "      <td>-0.000666</td>\n",
       "      <td>0.003416</td>\n",
       "      <td>-0.006812</td>\n",
       "      <td>-0.009825</td>\n",
       "      <td>0.004909</td>\n",
       "      <td>-0.019783</td>\n",
       "      <td>0.012778</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000291</td>\n",
       "      <td>-0.001245</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.730946</td>\n",
       "      <td>0.269054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.007649</td>\n",
       "      <td>-0.032243</td>\n",
       "      <td>0.013790</td>\n",
       "      <td>-0.007323</td>\n",
       "      <td>0.007871</td>\n",
       "      <td>0.022194</td>\n",
       "      <td>0.022763</td>\n",
       "      <td>-0.013405</td>\n",
       "      <td>0.011214</td>\n",
       "      <td>0.010168</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000179</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>-0.005593</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.681749</td>\n",
       "      <td>0.318251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.008614</td>\n",
       "      <td>0.021736</td>\n",
       "      <td>-0.014558</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.009667</td>\n",
       "      <td>-0.006560</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>-0.006437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004410</td>\n",
       "      <td>-0.010453</td>\n",
       "      <td>-0.001430</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.607465</td>\n",
       "      <td>0.392535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.005371</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>-0.004048</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>-0.015927</td>\n",
       "      <td>0.010633</td>\n",
       "      <td>-0.006541</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>-0.009816</td>\n",
       "      <td>-0.016539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.004244</td>\n",
       "      <td>-0.001100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.754843</td>\n",
       "      <td>0.245157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EMB_00_nan  EMB_01_nan  EMB_02_nan  EMB_03_nan  EMB_04_nan  EMB_05_nan  \\\n",
       "0   -0.003037   -0.007141   -0.011213   -0.009984   -0.017912    0.006851   \n",
       "1    0.020391    0.012623    0.001739    0.006033    0.011504   -0.000077   \n",
       "2   -0.008391    0.006389   -0.005018    0.005226   -0.010767   -0.006289   \n",
       "3    0.028635    0.005089    0.000495    0.000631    0.018450    0.015206   \n",
       "4    0.015572   -0.006919   -0.000248    0.003251   -0.006207   -0.009328   \n",
       "5    0.012488    0.010970    0.011845   -0.003121    0.011537    0.009381   \n",
       "6    0.015535    0.011653    0.010402   -0.000666    0.003416   -0.006812   \n",
       "7    0.007649   -0.032243    0.013790   -0.007323    0.007871    0.022194   \n",
       "8   -0.008614    0.021736   -0.014558    0.007941    0.001192    0.009667   \n",
       "9   -0.005371    0.006275   -0.004048    0.005733   -0.015927    0.010633   \n",
       "\n",
       "   EMB_06_nan  EMB_07_nan  EMB_08_nan  EMB_09_nan  ...  EMB_61_nan_shapley  \\\n",
       "0    0.010962   -0.003464    0.029793    0.002243  ...           -0.000259   \n",
       "1   -0.004077   -0.012035   -0.006936   -0.007154  ...            0.001213   \n",
       "2   -0.011314    0.005314    0.008374    0.012083  ...            0.001760   \n",
       "3    0.014947    0.007226   -0.000419   -0.004884  ...            0.001145   \n",
       "4   -0.008082   -0.020240   -0.018865   -0.005995  ...            0.001787   \n",
       "5   -0.006645    0.013332    0.002917   -0.011121  ...            0.001826   \n",
       "6   -0.009825    0.004909   -0.019783    0.012778  ...           -0.000291   \n",
       "7    0.022763   -0.013405    0.011214    0.010168  ...           -0.000179   \n",
       "8   -0.006560    0.001623    0.000762   -0.006437  ...            0.004410   \n",
       "9   -0.006541    0.006884   -0.009816   -0.016539  ...            0.001190   \n",
       "\n",
       "   EMB_62_nan_shapley  EMB_63_nan_shapley  is_married_encoded_nan  \\\n",
       "0            0.005541            0.000083                       0   \n",
       "1            0.001441            0.000762                       0   \n",
       "2            0.003575           -0.002715                       0   \n",
       "3            0.003794           -0.000589                       0   \n",
       "4            0.004394           -0.001818                       0   \n",
       "5           -0.016766           -0.005733                       1   \n",
       "6           -0.001245            0.001790                       1   \n",
       "7            0.001657           -0.005593                       1   \n",
       "8           -0.010453           -0.001430                       0   \n",
       "9            0.004244           -0.001100                       0   \n",
       "\n",
       "   pred_is_married_encoded_nan  pred_is_married_encoded_nan_best0  \\\n",
       "0                            0                                  0   \n",
       "1                            0                                  0   \n",
       "2                            0                                  0   \n",
       "3                            0                                  0   \n",
       "4                            0                                  0   \n",
       "5                            0                                  0   \n",
       "6                            0                                  0   \n",
       "7                            0                                  0   \n",
       "8                            0                                  0   \n",
       "9                            0                                  0   \n",
       "\n",
       "   pred_is_married_encoded_nan_best1  pred_is_married_encoded_nan_best2  \\\n",
       "0                                  0                                  0   \n",
       "1                                  0                                  0   \n",
       "2                                  0                                  0   \n",
       "3                                  0                                  0   \n",
       "4                                  0                                  0   \n",
       "5                                  0                                  0   \n",
       "6                                  0                                  0   \n",
       "7                                  0                                  0   \n",
       "8                                  0                                  0   \n",
       "9                                  0                                  0   \n",
       "\n",
       "     prob_0    prob_1  \n",
       "0  0.730504  0.269496  \n",
       "1  0.691984  0.308016  \n",
       "2  0.657182  0.342818  \n",
       "3  0.537598  0.462402  \n",
       "4  0.785848  0.214152  \n",
       "5  0.690500  0.309500  \n",
       "6  0.730946  0.269054  \n",
       "7  0.681749  0.318251  \n",
       "8  0.607465  0.392535  \n",
       "9  0.754843  0.245157  \n",
       "\n",
       "[10 rows x 135 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# asset 실행\n",
    "train_asset_structure=run(step, pipeline, asset_structure)\n",
    "\n",
    "# train asset의 결과 dataframe은 train_asset_structure.data['dataframe']으로 확인할 수 있습니다.\n",
    "train_asset_structure.data['dataframe'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2f82f0-1e6c-4af5-b842-78d428c1e6f3",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Inference workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e052e1b-3478-47f8-8c6d-62aa4474b591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[2023-11-09 06:50:11,940][PROCESS][INFO]: You did not write any << s3_private_key_file >> in the config yaml file. When you wanna get data from s3 storage, \n",
      "                                 you have to write the s3_private_key_file path or set << ACCESS_KEY, SECRET_KEY >> in your os environment. \n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:50:11,943][PROCESS][INFO]: Start setting-up << input >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[92m[2023-11-09 06:50:11,946][PROCESS][INFO]: Now << local >> asset_source_code mode: <input> asset exists.\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:50:11,949][PROCESS][INFO]: Start setting-up << preprocess >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[92m[2023-11-09 06:50:11,951][PROCESS][INFO]: Now << local >> asset_source_code mode: <preprocess> asset exists.\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:50:11,954][PROCESS][INFO]: Start setting-up << inference >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:50:11,958][PROCESS][INFO]: << inference >> asset had already been created at 2023-11-09 06:38:43.715859\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:50:11,961][PROCESS][INFO]: Start setting-up << result >> asset @ << assets >> directory.\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:50:11,964][PROCESS][INFO]: << result >> asset had already been created at 2023-11-09 06:45:24.781921\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:50:11,967][PROCESS][INFO]: >>> Ignored installing << pandas==1.5.3 >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:50:11,969][PROCESS][INFO]: >>> Ignored installing << pandas==1.5.3 >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:50:11,972][PROCESS][INFO]: >>> Ignored installing << pandas==1.5.3 >>. Another version would be installed in the previous step.\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:50:11,974][PROCESS][INFO]: ======================================== Start dependency installation : << input >> \u001b[0m\n",
      "\u001b[94m[2023-11-09 06:50:11,977][PROCESS][INFO]: Start checking existence & installing package - pandas==1.5.3 | Progress: ( 1 / 1 total packages ) \u001b[0m\n",
      "\u001b[92m[2023-11-09 06:50:11,980][PROCESS][INFO]: [OK] << pandas==1.5.3 >> already exists\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:50:11,982][PROCESS][INFO]: ======================================== Start dependency installation : << force-reinstall >> \u001b[0m\n",
      "\u001b[94m[2023-11-09 06:50:11,984][PROCESS][INFO]: ======================================== Finish dependency installation \n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 아래는 Inference 시 필요한 라이브러리를 설치하는 코드입니다. library 설치 에러가 발생하면 아래 셀을 재실행 해주세요\n",
    "external_load_data(pipelines[1], alo.external_path, alo.external_path_permission, alo.control['get_external_data'])\n",
    "pipeline = pipelines[1]\n",
    "alo.install_steps(pipeline, alo.control[\"get_asset_source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34d56f68-61d8-4a05-8dab-3e2f936b02d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기 data structure 구성\n",
    "envs, args, data, config = {}, {}, {}, {}\n",
    "init_asset_structure = AssetStructure(envs, args, data, config)\n",
    "# logger init\n",
    "alo.set_proc_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f681c8a8-ffde-4f59-a694-1b3849b90dd4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 0. Input asset \n",
    "##### Input asset의 arguments 수정 및 확인\n",
    "- 필요한경우 input_args의 항목을 ***asset_structure.args[argument명]=value입력*** 을 통해 변경할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2f43e8e-5a9a-4cbc-b2b5-f548d92b3feb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_path': 'inference',\n",
       " 'x_columns': None,\n",
       " 'use_all_x': True,\n",
       " 'y_column': None,\n",
       " 'groupkey_columns': None,\n",
       " 'drop_columns': None,\n",
       " 'time_column': None,\n",
       " 'concat_dataframes': None,\n",
       " 'encoding': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GCR asset 순서에 따라 step 순서를 입력합니다. (input(0) - preprocess(2) - inference(3) - result(4))\n",
    "step = 0 \n",
    "asset_structure = copy.deepcopy(init_asset_structure)\n",
    "asset_structure.args = alo.get_args(pipeline, step)\n",
    "\n",
    "# 아래 주석을 풀어 input asset argument를 원하는 값으로 수정합니다.\n",
    "# asset_structure.args['x_columns'] = ['']\n",
    "asset_structure.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f705ac75-11a8-4093-9531-3b09de8fc38e",
   "metadata": {},
   "source": [
    "##### Input asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "026f2355-99c7-437f-8274-dbed7aa968d8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-11-09 06:50:12,014][USER][INFO][inference_pipeline][input]: >> Load path : ['/home/jovyan/gcr/alo//input/inference/inference/']\n",
      "[2023-11-09 06:50:12,028][USER][INFO][inference_pipeline][input]: >> The file for batch data has been loaded. (File name: /home/jovyan/gcr/alo//input/inference/inference/inference.csv)\n",
      "[2023-11-09 06:50:12,031][USER][INFO][inference_pipeline][input]: You set the << use_all_x >> as << True >> in the yaml file. So skip checking dataframe columns existence.\n",
      "[2023-11-09 06:50:12,034][USER][INFO][inference_pipeline][input]: ==================== Success loading dataframe ====================\n",
      "[2023-11-09 06:50:12,036][USER][INFO][inference_pipeline][input]: >> Start processing ignore columns & drop columns: ['/home/jovyan/gcr/alo//input/inference/inference/inference.csv']\n",
      "[2023-11-09 06:50:12,040][USER][INFO][inference_pipeline][input]: >> You set the << use_all_x >> parameter as << True >> in your config yaml. (So, these x_columns are used: ['EMB_49', 'EMB_02', 'EMB_15', 'EMB_55', 'EMB_56', 'EMB_18', 'EMB_54', 'EMB_29', 'EMB_25', 'EMB_50', 'EMB_48', 'EMB_23', 'EMB_63', 'EMB_11', 'EMB_09', 'EMB_21', 'EMB_34', 'EMB_17', 'EMB_43', 'EMB_52', 'EMB_22', 'EMB_36', 'EMB_61', 'EMB_12', 'EMB_10', 'EMB_00', 'EMB_31', 'EMB_62', 'EMB_38', 'EMB_26', 'EMB_57', 'EMB_28', 'EMB_05', 'EMB_20', 'EMB_07', 'EMB_46', 'EMB_44', 'EMB_39', 'EMB_60', 'EMB_40', 'EMB_24', 'EMB_58', 'EMB_37', 'EMB_51', 'EMB_35', 'EMB_13', 'EMB_42', 'EMB_04', 'EMB_06', 'EMB_14', 'EMB_16', 'EMB_19', 'EMB_53', 'EMB_30', 'EMB_45', 'EMB_01', 'EMB_27', 'EMB_41', 'EMB_03', 'EMB_08', 'EMB_59', 'EMB_32', 'EMB_47', 'EMB_33'] )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[2023-11-09 06:50:12,010][ASSET][INFO][inference_pipeline][input]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-09 06:50:12\n",
      "- current step      : input\n",
      "- asset branch.     : tabular_2.0\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path'])\n",
      "- load args. keys   : dict_keys(['input_path', 'x_columns', 'use_all_x', 'y_column', 'groupkey_columns', 'drop_columns', 'time_column', 'concat_dataframes', 'encoding'])\n",
      "- load config. keys : dict_keys(['meta'])\n",
      "- load data keys    : dict_keys([])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:50:12,041][ASSET][INFO][inference_pipeline][input]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-09 06:50:12\n",
      "- current step      : input\n",
      "- save config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:50:12,043][PROCESS][INFO]: ==================== Finish pipeline: inference_pipeline / step: input\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMB_00</th>\n",
       "      <th>EMB_01</th>\n",
       "      <th>EMB_02</th>\n",
       "      <th>EMB_03</th>\n",
       "      <th>EMB_04</th>\n",
       "      <th>EMB_05</th>\n",
       "      <th>EMB_06</th>\n",
       "      <th>EMB_07</th>\n",
       "      <th>EMB_08</th>\n",
       "      <th>EMB_09</th>\n",
       "      <th>...</th>\n",
       "      <th>EMB_54</th>\n",
       "      <th>EMB_55</th>\n",
       "      <th>EMB_56</th>\n",
       "      <th>EMB_57</th>\n",
       "      <th>EMB_58</th>\n",
       "      <th>EMB_59</th>\n",
       "      <th>EMB_60</th>\n",
       "      <th>EMB_61</th>\n",
       "      <th>EMB_62</th>\n",
       "      <th>EMB_63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.002611</td>\n",
       "      <td>-0.002001</td>\n",
       "      <td>-0.007244</td>\n",
       "      <td>-0.008264</td>\n",
       "      <td>-0.009245</td>\n",
       "      <td>0.004773</td>\n",
       "      <td>-0.004757</td>\n",
       "      <td>-0.009132</td>\n",
       "      <td>-0.003980</td>\n",
       "      <td>-0.003986</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>-0.016771</td>\n",
       "      <td>-0.032969</td>\n",
       "      <td>0.012735</td>\n",
       "      <td>-0.006551</td>\n",
       "      <td>-0.006155</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>0.012964</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>0.004174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006203</td>\n",
       "      <td>-0.031904</td>\n",
       "      <td>-0.005630</td>\n",
       "      <td>-0.002246</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>-0.000785</td>\n",
       "      <td>-0.013895</td>\n",
       "      <td>-0.060086</td>\n",
       "      <td>0.012112</td>\n",
       "      <td>0.010161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022778</td>\n",
       "      <td>-0.007051</td>\n",
       "      <td>0.014345</td>\n",
       "      <td>0.012054</td>\n",
       "      <td>0.025028</td>\n",
       "      <td>0.003834</td>\n",
       "      <td>0.009762</td>\n",
       "      <td>0.003318</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>-0.006457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.013035</td>\n",
       "      <td>-0.031346</td>\n",
       "      <td>-0.007259</td>\n",
       "      <td>-0.027150</td>\n",
       "      <td>0.013176</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.008632</td>\n",
       "      <td>-0.018074</td>\n",
       "      <td>0.011783</td>\n",
       "      <td>0.013075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010142</td>\n",
       "      <td>-0.019521</td>\n",
       "      <td>-0.003204</td>\n",
       "      <td>-0.009010</td>\n",
       "      <td>-0.009577</td>\n",
       "      <td>0.012087</td>\n",
       "      <td>0.012509</td>\n",
       "      <td>-0.007436</td>\n",
       "      <td>0.033228</td>\n",
       "      <td>0.020525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011535</td>\n",
       "      <td>0.002678</td>\n",
       "      <td>0.008933</td>\n",
       "      <td>-0.007592</td>\n",
       "      <td>0.013526</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>-0.004640</td>\n",
       "      <td>0.012302</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>-0.008446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010726</td>\n",
       "      <td>-0.002434</td>\n",
       "      <td>-0.012074</td>\n",
       "      <td>0.027268</td>\n",
       "      <td>-0.002489</td>\n",
       "      <td>0.012693</td>\n",
       "      <td>-0.000898</td>\n",
       "      <td>-0.006660</td>\n",
       "      <td>0.020033</td>\n",
       "      <td>-0.011353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000464</td>\n",
       "      <td>-0.001815</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>-0.005883</td>\n",
       "      <td>0.020563</td>\n",
       "      <td>0.008915</td>\n",
       "      <td>0.023891</td>\n",
       "      <td>-0.008433</td>\n",
       "      <td>0.009153</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007791</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>-0.009352</td>\n",
       "      <td>-0.004140</td>\n",
       "      <td>-0.017093</td>\n",
       "      <td>-0.012221</td>\n",
       "      <td>-0.006049</td>\n",
       "      <td>-0.004401</td>\n",
       "      <td>0.004302</td>\n",
       "      <td>-0.003082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.017396</td>\n",
       "      <td>0.018430</td>\n",
       "      <td>-0.019600</td>\n",
       "      <td>-0.000973</td>\n",
       "      <td>0.005116</td>\n",
       "      <td>0.015510</td>\n",
       "      <td>-0.021879</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>-0.019197</td>\n",
       "      <td>0.022846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012552</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>-0.007688</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>-0.007874</td>\n",
       "      <td>-0.013986</td>\n",
       "      <td>0.018652</td>\n",
       "      <td>0.010788</td>\n",
       "      <td>-0.002692</td>\n",
       "      <td>-0.002896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.002049</td>\n",
       "      <td>-0.003535</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>-0.010233</td>\n",
       "      <td>-0.011990</td>\n",
       "      <td>0.010471</td>\n",
       "      <td>0.010511</td>\n",
       "      <td>0.006122</td>\n",
       "      <td>0.018677</td>\n",
       "      <td>-0.002852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>0.003313</td>\n",
       "      <td>-0.002718</td>\n",
       "      <td>0.027768</td>\n",
       "      <td>0.012286</td>\n",
       "      <td>-0.015003</td>\n",
       "      <td>-0.010612</td>\n",
       "      <td>-0.012544</td>\n",
       "      <td>0.022089</td>\n",
       "      <td>-0.005592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.003612</td>\n",
       "      <td>-0.013574</td>\n",
       "      <td>-0.000596</td>\n",
       "      <td>0.011884</td>\n",
       "      <td>-0.016282</td>\n",
       "      <td>0.018033</td>\n",
       "      <td>-0.010712</td>\n",
       "      <td>-0.010708</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>0.023245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>-0.001595</td>\n",
       "      <td>0.007095</td>\n",
       "      <td>-0.018613</td>\n",
       "      <td>0.012829</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>-0.007128</td>\n",
       "      <td>-0.000380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002887</td>\n",
       "      <td>-0.014903</td>\n",
       "      <td>-0.013136</td>\n",
       "      <td>-0.017121</td>\n",
       "      <td>-0.001242</td>\n",
       "      <td>0.012092</td>\n",
       "      <td>0.026471</td>\n",
       "      <td>-0.005164</td>\n",
       "      <td>0.040155</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009327</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>-0.014485</td>\n",
       "      <td>-0.006645</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>0.026861</td>\n",
       "      <td>0.007188</td>\n",
       "      <td>0.003539</td>\n",
       "      <td>0.039540</td>\n",
       "      <td>0.024405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.023049</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>-0.014058</td>\n",
       "      <td>-0.018598</td>\n",
       "      <td>0.010358</td>\n",
       "      <td>0.016791</td>\n",
       "      <td>-0.012068</td>\n",
       "      <td>0.025469</td>\n",
       "      <td>0.021957</td>\n",
       "      <td>-0.022532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>-0.000346</td>\n",
       "      <td>-0.009741</td>\n",
       "      <td>0.027545</td>\n",
       "      <td>0.003370</td>\n",
       "      <td>0.023169</td>\n",
       "      <td>0.017635</td>\n",
       "      <td>-0.004659</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>-0.012603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     EMB_00    EMB_01    EMB_02    EMB_03    EMB_04    EMB_05    EMB_06  \\\n",
       "0 -0.002611 -0.002001 -0.007244 -0.008264 -0.009245  0.004773 -0.004757   \n",
       "1  0.006203 -0.031904 -0.005630 -0.002246 -0.000162 -0.000785 -0.013895   \n",
       "2 -0.013035 -0.031346 -0.007259 -0.027150  0.013176  0.001905  0.008632   \n",
       "3  0.011535  0.002678  0.008933 -0.007592  0.013526  0.010309 -0.004640   \n",
       "4 -0.000464 -0.001815  0.007813 -0.005883  0.020563  0.008915  0.023891   \n",
       "5  0.017396  0.018430 -0.019600 -0.000973  0.005116  0.015510 -0.021879   \n",
       "6 -0.002049 -0.003535  0.003486 -0.010233 -0.011990  0.010471  0.010511   \n",
       "7 -0.003612 -0.013574 -0.000596  0.011884 -0.016282  0.018033 -0.010712   \n",
       "8  0.002887 -0.014903 -0.013136 -0.017121 -0.001242  0.012092  0.026471   \n",
       "9  0.023049  0.001317 -0.014058 -0.018598  0.010358  0.016791 -0.012068   \n",
       "\n",
       "     EMB_07    EMB_08    EMB_09  ...    EMB_54    EMB_55    EMB_56    EMB_57  \\\n",
       "0 -0.009132 -0.003980 -0.003986  ... -0.008983 -0.016771 -0.032969  0.012735   \n",
       "1 -0.060086  0.012112  0.010161  ...  0.022778 -0.007051  0.014345  0.012054   \n",
       "2 -0.018074  0.011783  0.013075  ...  0.010142 -0.019521 -0.003204 -0.009010   \n",
       "3  0.012302  0.000240 -0.008446  ...  0.010726 -0.002434 -0.012074  0.027268   \n",
       "4 -0.008433  0.009153  0.001672  ...  0.007791  0.004728 -0.009352 -0.004140   \n",
       "5  0.007576 -0.019197  0.022846  ...  0.012552  0.002626 -0.007688  0.005242   \n",
       "6  0.006122  0.018677 -0.002852  ...  0.008647  0.003313 -0.002718  0.027768   \n",
       "7 -0.010708  0.008789  0.023245  ...  0.005225  0.002043 -0.001595  0.007095   \n",
       "8 -0.005164  0.040155  0.000823  ... -0.009327  0.000451 -0.014485 -0.006645   \n",
       "9  0.025469  0.021957 -0.022532  ...  0.006100 -0.000346 -0.009741  0.027545   \n",
       "\n",
       "     EMB_58    EMB_59    EMB_60    EMB_61    EMB_62    EMB_63  \n",
       "0 -0.006551 -0.006155  0.003361  0.012964  0.001979  0.004174  \n",
       "1  0.025028  0.003834  0.009762  0.003318  0.005872 -0.006457  \n",
       "2 -0.009577  0.012087  0.012509 -0.007436  0.033228  0.020525  \n",
       "3 -0.002489  0.012693 -0.000898 -0.006660  0.020033 -0.011353  \n",
       "4 -0.017093 -0.012221 -0.006049 -0.004401  0.004302 -0.003082  \n",
       "5 -0.007874 -0.013986  0.018652  0.010788 -0.002692 -0.002896  \n",
       "6  0.012286 -0.015003 -0.010612 -0.012544  0.022089 -0.005592  \n",
       "7 -0.018613  0.012829  0.010274  0.000282 -0.007128 -0.000380  \n",
       "8 -0.001124  0.026861  0.007188  0.003539  0.039540  0.024405  \n",
       "9  0.003370  0.023169  0.017635 -0.004659  0.005299 -0.012603  \n",
       "\n",
       "[10 rows x 64 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# asset 실행\n",
    "input_asset_structure=run(step, pipeline, asset_structure)\n",
    "\n",
    "# input asset의 결과 dataframe은 input_asset_structure.data['dataframe']으로 확인할 수 있습니다.\n",
    "input_asset_structure.data['dataframe'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ddf39d-af5c-48bd-9a96-a3543e030b2c",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "### 1. Preprocess asset \n",
    "##### Preprocess asset의 args수정 및 확인\n",
    "- 필요한경우 preprocess_args의 항목을 ***asset_structure.args[argument명]=value입력*** 을 통해 변경할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b486fd42-87de-4c15-aa77-324cb77415b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'handling_missing': 'interpolation',\n",
       " 'handling_encoding_y_column': None,\n",
       " 'limit_encoding_categories': 30,\n",
       " 'load_train_preprocess': True}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GCR asset 순서에 따라 step 순서를 입력합니다. (input(0) - preprocess(2) - inference(3) - result(4))\n",
    "step = 1 \n",
    "asset_structure = copy.deepcopy(input_asset_structure)\n",
    "asset_structure.args = alo.get_args(pipeline, step)\n",
    "\n",
    "# 아래 주석을 풀어 preprocess asset argument를 원하는 값으로 수정합니다.\n",
    "# asset_structure.args['x_columns'] = ['']\n",
    "asset_structure.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6a36f8-55c3-4e3e-8879-d8aeb7f9ecac",
   "metadata": {},
   "source": [
    "##### Preprocess asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f690c108-afc0-48e3-9b04-85a4f498c8da",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m[2023-11-09 06:50:12,076][ASSET][INFO][inference_pipeline][preprocess]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/gcr/alo//.train_artifacts/models/preprocess/\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:50:12,078][ASSET][INFO][inference_pipeline][preprocess]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-09 06:50:12\n",
      "- current step      : preprocess\n",
      "- asset branch.     : release-1.2\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['handling_missing', 'handling_encoding_y_column', 'limit_encoding_categories', 'load_train_preprocess'])\n",
      "- load config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns'])\n",
      "- load data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "['EMB_49_nan', 'EMB_02_nan', 'EMB_15_nan', 'EMB_55_nan', 'EMB_56_nan', 'EMB_18_nan', 'EMB_54_nan', 'EMB_29_nan', 'EMB_25_nan', 'EMB_50_nan', 'EMB_48_nan', 'EMB_23_nan', 'EMB_63_nan', 'EMB_11_nan', 'EMB_09_nan', 'EMB_21_nan', 'EMB_34_nan', 'EMB_17_nan', 'EMB_43_nan', 'EMB_52_nan', 'EMB_22_nan', 'EMB_36_nan', 'EMB_61_nan', 'EMB_12_nan', 'EMB_10_nan', 'EMB_00_nan', 'EMB_31_nan', 'EMB_62_nan', 'EMB_38_nan', 'EMB_26_nan', 'EMB_57_nan', 'EMB_28_nan', 'EMB_05_nan', 'EMB_20_nan', 'EMB_07_nan', 'EMB_46_nan', 'EMB_44_nan', 'EMB_39_nan', 'EMB_60_nan', 'EMB_40_nan', 'EMB_24_nan', 'EMB_58_nan', 'EMB_37_nan', 'EMB_51_nan', 'EMB_35_nan', 'EMB_13_nan', 'EMB_42_nan', 'EMB_04_nan', 'EMB_06_nan', 'EMB_14_nan', 'EMB_16_nan', 'EMB_19_nan', 'EMB_53_nan', 'EMB_30_nan', 'EMB_45_nan', 'EMB_01_nan', 'EMB_27_nan', 'EMB_41_nan', 'EMB_03_nan', 'EMB_08_nan', 'EMB_59_nan', 'EMB_32_nan', 'EMB_47_nan', 'EMB_33_nan'] \n",
      "\u001b[94m[2023-11-09 06:50:12,085][ASSET][INFO][inference_pipeline][preprocess]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-09 06:50:12\n",
      "- current step      : preprocess\n",
      "- save config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:50:12,087][PROCESS][INFO]: ==================== Finish pipeline: inference_pipeline / step: preprocess\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMB_49</th>\n",
       "      <th>EMB_02</th>\n",
       "      <th>EMB_15</th>\n",
       "      <th>EMB_55</th>\n",
       "      <th>EMB_56</th>\n",
       "      <th>EMB_18</th>\n",
       "      <th>EMB_54</th>\n",
       "      <th>EMB_29</th>\n",
       "      <th>EMB_25</th>\n",
       "      <th>EMB_50</th>\n",
       "      <th>...</th>\n",
       "      <th>EMB_45_nan</th>\n",
       "      <th>EMB_01_nan</th>\n",
       "      <th>EMB_27_nan</th>\n",
       "      <th>EMB_41_nan</th>\n",
       "      <th>EMB_03_nan</th>\n",
       "      <th>EMB_08_nan</th>\n",
       "      <th>EMB_59_nan</th>\n",
       "      <th>EMB_32_nan</th>\n",
       "      <th>EMB_47_nan</th>\n",
       "      <th>EMB_33_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010146</td>\n",
       "      <td>-0.007244</td>\n",
       "      <td>-0.001716</td>\n",
       "      <td>-0.016771</td>\n",
       "      <td>-0.032969</td>\n",
       "      <td>-0.005313</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.005070</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.005993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010868</td>\n",
       "      <td>-0.002001</td>\n",
       "      <td>0.004750</td>\n",
       "      <td>-0.006613</td>\n",
       "      <td>-0.008264</td>\n",
       "      <td>-0.003980</td>\n",
       "      <td>-0.006155</td>\n",
       "      <td>0.009096</td>\n",
       "      <td>0.004048</td>\n",
       "      <td>0.015179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018737</td>\n",
       "      <td>-0.005630</td>\n",
       "      <td>-0.017798</td>\n",
       "      <td>-0.007051</td>\n",
       "      <td>0.014345</td>\n",
       "      <td>0.007672</td>\n",
       "      <td>0.022778</td>\n",
       "      <td>0.014511</td>\n",
       "      <td>-0.004269</td>\n",
       "      <td>-0.028216</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008147</td>\n",
       "      <td>-0.031904</td>\n",
       "      <td>-0.022476</td>\n",
       "      <td>0.018488</td>\n",
       "      <td>-0.002246</td>\n",
       "      <td>0.012112</td>\n",
       "      <td>0.003834</td>\n",
       "      <td>0.012858</td>\n",
       "      <td>-0.019594</td>\n",
       "      <td>-0.009072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007747</td>\n",
       "      <td>-0.007259</td>\n",
       "      <td>-0.003907</td>\n",
       "      <td>-0.019521</td>\n",
       "      <td>-0.003204</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.010142</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>-0.037842</td>\n",
       "      <td>-0.019766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002749</td>\n",
       "      <td>-0.031346</td>\n",
       "      <td>-0.004517</td>\n",
       "      <td>0.022099</td>\n",
       "      <td>-0.027150</td>\n",
       "      <td>0.011783</td>\n",
       "      <td>0.012087</td>\n",
       "      <td>0.032098</td>\n",
       "      <td>0.032730</td>\n",
       "      <td>0.004925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003393</td>\n",
       "      <td>0.008933</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>-0.002434</td>\n",
       "      <td>-0.012074</td>\n",
       "      <td>-0.008998</td>\n",
       "      <td>0.010726</td>\n",
       "      <td>-0.002448</td>\n",
       "      <td>-0.014632</td>\n",
       "      <td>-0.001509</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003900</td>\n",
       "      <td>0.002678</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>-0.007592</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.012693</td>\n",
       "      <td>0.013224</td>\n",
       "      <td>0.002934</td>\n",
       "      <td>-0.017633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010472</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>-0.016032</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>-0.009352</td>\n",
       "      <td>0.003457</td>\n",
       "      <td>0.007791</td>\n",
       "      <td>0.007896</td>\n",
       "      <td>0.012731</td>\n",
       "      <td>0.012376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>-0.001815</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>-0.006750</td>\n",
       "      <td>-0.005883</td>\n",
       "      <td>0.009153</td>\n",
       "      <td>-0.012221</td>\n",
       "      <td>0.018701</td>\n",
       "      <td>0.004062</td>\n",
       "      <td>-0.001523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.011779</td>\n",
       "      <td>-0.019600</td>\n",
       "      <td>-0.021988</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>-0.007688</td>\n",
       "      <td>0.017618</td>\n",
       "      <td>0.012552</td>\n",
       "      <td>-0.003714</td>\n",
       "      <td>-0.044726</td>\n",
       "      <td>0.018596</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017815</td>\n",
       "      <td>0.018430</td>\n",
       "      <td>-0.035370</td>\n",
       "      <td>0.017522</td>\n",
       "      <td>-0.000973</td>\n",
       "      <td>-0.019197</td>\n",
       "      <td>-0.013986</td>\n",
       "      <td>0.028463</td>\n",
       "      <td>0.009123</td>\n",
       "      <td>0.002543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.015086</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>-0.005621</td>\n",
       "      <td>0.003313</td>\n",
       "      <td>-0.002718</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>-0.001996</td>\n",
       "      <td>-0.007421</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020514</td>\n",
       "      <td>-0.003535</td>\n",
       "      <td>0.010746</td>\n",
       "      <td>0.008236</td>\n",
       "      <td>-0.010233</td>\n",
       "      <td>0.018677</td>\n",
       "      <td>-0.015003</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.008515</td>\n",
       "      <td>0.010995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.024821</td>\n",
       "      <td>-0.000596</td>\n",
       "      <td>-0.001121</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>-0.001595</td>\n",
       "      <td>0.005227</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>-0.025767</td>\n",
       "      <td>-0.031729</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>-0.013574</td>\n",
       "      <td>0.005003</td>\n",
       "      <td>0.020067</td>\n",
       "      <td>0.011884</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>0.012829</td>\n",
       "      <td>0.010682</td>\n",
       "      <td>-0.034486</td>\n",
       "      <td>-0.032593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.031485</td>\n",
       "      <td>-0.013136</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>-0.014485</td>\n",
       "      <td>0.029922</td>\n",
       "      <td>-0.009327</td>\n",
       "      <td>-0.006452</td>\n",
       "      <td>-0.014477</td>\n",
       "      <td>-0.019159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>-0.014903</td>\n",
       "      <td>-0.014588</td>\n",
       "      <td>0.022280</td>\n",
       "      <td>-0.017121</td>\n",
       "      <td>0.040155</td>\n",
       "      <td>0.026861</td>\n",
       "      <td>-0.000553</td>\n",
       "      <td>-0.030020</td>\n",
       "      <td>-0.012125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.009314</td>\n",
       "      <td>-0.014058</td>\n",
       "      <td>0.018915</td>\n",
       "      <td>-0.000346</td>\n",
       "      <td>-0.009741</td>\n",
       "      <td>-0.019416</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>-0.034596</td>\n",
       "      <td>-0.047293</td>\n",
       "      <td>-0.008733</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005962</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.015445</td>\n",
       "      <td>0.012442</td>\n",
       "      <td>-0.018598</td>\n",
       "      <td>0.021957</td>\n",
       "      <td>0.023169</td>\n",
       "      <td>0.014019</td>\n",
       "      <td>-0.014469</td>\n",
       "      <td>-0.008606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     EMB_49    EMB_02    EMB_15    EMB_55    EMB_56    EMB_18    EMB_54  \\\n",
       "0  0.010146 -0.007244 -0.001716 -0.016771 -0.032969 -0.005313 -0.008983   \n",
       "1  0.018737 -0.005630 -0.017798 -0.007051  0.014345  0.007672  0.022778   \n",
       "2  0.007747 -0.007259 -0.003907 -0.019521 -0.003204  0.000379  0.010142   \n",
       "3  0.003393  0.008933  0.009891 -0.002434 -0.012074 -0.008998  0.010726   \n",
       "4  0.010472  0.007813 -0.016032  0.004728 -0.009352  0.003457  0.007791   \n",
       "5  0.011779 -0.019600 -0.021988  0.002626 -0.007688  0.017618  0.012552   \n",
       "6  0.015086  0.003486 -0.005621  0.003313 -0.002718  0.006186  0.008647   \n",
       "7  0.024821 -0.000596 -0.001121  0.002043 -0.001595  0.005227  0.005225   \n",
       "8  0.031485 -0.013136  0.000392  0.000451 -0.014485  0.029922 -0.009327   \n",
       "9  0.009314 -0.014058  0.018915 -0.000346 -0.009741 -0.019416  0.006100   \n",
       "\n",
       "     EMB_29    EMB_25    EMB_50  ...  EMB_45_nan  EMB_01_nan  EMB_27_nan  \\\n",
       "0  0.005070  0.002706  0.005993  ...    0.010868   -0.002001    0.004750   \n",
       "1  0.014511 -0.004269 -0.028216  ...   -0.008147   -0.031904   -0.022476   \n",
       "2  0.002430 -0.037842 -0.019766  ...    0.002749   -0.031346   -0.004517   \n",
       "3 -0.002448 -0.014632 -0.001509  ...   -0.003900    0.002678    0.000816   \n",
       "4  0.007896  0.012731  0.012376  ...    0.000877   -0.001815    0.001254   \n",
       "5 -0.003714 -0.044726  0.018596  ...   -0.017815    0.018430   -0.035370   \n",
       "6  0.002292 -0.001996 -0.007421  ...   -0.020514   -0.003535    0.010746   \n",
       "7 -0.025767 -0.031729  0.001422  ...    0.000501   -0.013574    0.005003   \n",
       "8 -0.006452 -0.014477 -0.019159  ...    0.003803   -0.014903   -0.014588   \n",
       "9 -0.034596 -0.047293 -0.008733  ...   -0.005962    0.001317    0.015445   \n",
       "\n",
       "   EMB_41_nan  EMB_03_nan  EMB_08_nan  EMB_59_nan  EMB_32_nan  EMB_47_nan  \\\n",
       "0   -0.006613   -0.008264   -0.003980   -0.006155    0.009096    0.004048   \n",
       "1    0.018488   -0.002246    0.012112    0.003834    0.012858   -0.019594   \n",
       "2    0.022099   -0.027150    0.011783    0.012087    0.032098    0.032730   \n",
       "3    0.000222   -0.007592    0.000240    0.012693    0.013224    0.002934   \n",
       "4   -0.006750   -0.005883    0.009153   -0.012221    0.018701    0.004062   \n",
       "5    0.017522   -0.000973   -0.019197   -0.013986    0.028463    0.009123   \n",
       "6    0.008236   -0.010233    0.018677   -0.015003    0.000845    0.008515   \n",
       "7    0.020067    0.011884    0.008789    0.012829    0.010682   -0.034486   \n",
       "8    0.022280   -0.017121    0.040155    0.026861   -0.000553   -0.030020   \n",
       "9    0.012442   -0.018598    0.021957    0.023169    0.014019   -0.014469   \n",
       "\n",
       "   EMB_33_nan  \n",
       "0    0.015179  \n",
       "1   -0.009072  \n",
       "2    0.004925  \n",
       "3   -0.017633  \n",
       "4   -0.001523  \n",
       "5    0.002543  \n",
       "6    0.010995  \n",
       "7   -0.032593  \n",
       "8   -0.012125  \n",
       "9   -0.008606  \n",
       "\n",
       "[10 rows x 128 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# asset 실행\n",
    "preprocess_asset_structure=run(step, pipeline, asset_structure)\n",
    "\n",
    "# preprocess asset의 결과 dataframe은 preprocess_asset_structure.data['dataframe']으로 확인할 수 있습니다.  \n",
    "preprocess_asset_structure.data['dataframe'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a66a6da-7efd-4c9f-92b4-b91366365db7",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2. Inference asset \n",
    "##### Inference asset의 args수정 및 확인\n",
    "- 필요한경우 inference_args의 항목을 ***asset_structure.args[argument명]=value입력*** 을 통해 변경할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13b21092-9b65-4de1-874e-46e8cbd96075",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_type': 'classification', 'run_shapley': False}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GCR asset 순서에 따라 step 순서를 입력합니다. (input(0) - preprocess(2) - inference(3) - result(4))\n",
    "step = 2 \n",
    "asset_structure = copy.deepcopy(preprocess_asset_structure)\n",
    "asset_structure.args = alo.get_args(pipeline, step)\n",
    "\n",
    "# 아래 주석을 풀어 inference asset argument를 원하는 값으로 수정합니다.\n",
    "# asset_structure.args['x_columns'] = ['']\n",
    "asset_structure.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5544d75-1e2f-4009-9e24-7cb91bc18ced",
   "metadata": {},
   "source": [
    "##### inference asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf9857de-2615-41ec-829f-cddb0808aab2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ################################### inference_init (sec):  0.0001456737518310547 ################################### \n",
      "\n",
      "\u001b[94m[2023-11-09 06:50:12,120][ASSET][INFO][inference_pipeline][inference]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-09 06:50:12\n",
      "- current step      : inference\n",
      "- asset branch.     : tcr_v1.1.1\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['model_type', 'run_shapley'])\n",
      "- load config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess'])\n",
      "- load data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[92m[2023-11-09 06:50:12,123][ASSET][INFO][inference_pipeline][inference]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/gcr/alo//.train_artifacts/models/train/\u001b[0m\n",
      "\u001b[92m[2023-11-09 06:50:12,124][ASSET][INFO][inference_pipeline][inference]: Successfully got << output path >> for saving your data into csv or jpg file: \n",
      " /home/jovyan/gcr/alo//.inference_artifacts/output/inference/ \n",
      " - [NOTE] The names of output file must be fixed as << output.csv, output.jpg >> \u001b[0m\n",
      "해당 column 은 Training 과정에 사용되지 않습니다. (column_name: ['EMB_49', 'EMB_02', 'EMB_15', 'EMB_55', 'EMB_56', 'EMB_18', 'EMB_54', 'EMB_50', 'EMB_25', 'EMB_29', 'EMB_48', 'EMB_23', 'EMB_63', 'EMB_11', 'EMB_09', 'EMB_21', 'EMB_34', 'EMB_17', 'EMB_43', 'EMB_52', 'EMB_22', 'EMB_36', 'EMB_61', 'EMB_12', 'EMB_10', 'EMB_00', 'EMB_31', 'EMB_62', 'EMB_38', 'EMB_26', 'EMB_57', 'EMB_28', 'EMB_05', 'EMB_20', 'EMB_07', 'EMB_46', 'EMB_44', 'EMB_39', 'EMB_60', 'EMB_40', 'EMB_24', 'EMB_58', 'EMB_37', 'EMB_51', 'EMB_35', 'EMB_13', 'EMB_42', 'EMB_04', 'EMB_06', 'EMB_14', 'EMB_16', 'EMB_19', 'EMB_53', 'EMB_30', 'EMB_45', 'EMB_01', 'EMB_27', 'EMB_41', 'EMB_03', 'EMB_08', 'EMB_59', 'EMB_32', 'EMB_47', 'EMB_33'])\n",
      "\u001b[92m[2023-11-09 06:50:12,128][ASSET][INFO][inference_pipeline][inference]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/gcr/alo//.train_artifacts/models/train/\u001b[0m\n",
      "[INFO] XAI 분석 시, 활용할 모델을 로드합니다.\n",
      "모델을 Load 완료 하였습니다. (모델 위치: /home/jovyan/gcr/alo//.train_artifacts/models/train/best_model_top0.pkl)\n",
      "\n",
      " ################################### inference_user_run (sec):  0.15259957313537598 ################################### \n",
      "\n",
      "\u001b[94m[2023-11-09 06:50:12,278][ASSET][INFO][inference_pipeline][inference]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-09 06:50:12\n",
      "- current step      : inference\n",
      "- save config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:50:12,280][PROCESS][INFO]: ==================== Finish pipeline: inference_pipeline / step: inference\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMB_00</th>\n",
       "      <th>EMB_01</th>\n",
       "      <th>EMB_02</th>\n",
       "      <th>EMB_03</th>\n",
       "      <th>EMB_04</th>\n",
       "      <th>EMB_05</th>\n",
       "      <th>EMB_06</th>\n",
       "      <th>EMB_07</th>\n",
       "      <th>EMB_08</th>\n",
       "      <th>EMB_09</th>\n",
       "      <th>...</th>\n",
       "      <th>EMB_55_nan</th>\n",
       "      <th>EMB_56_nan</th>\n",
       "      <th>EMB_57_nan</th>\n",
       "      <th>EMB_58_nan</th>\n",
       "      <th>EMB_59_nan</th>\n",
       "      <th>EMB_60_nan</th>\n",
       "      <th>EMB_61_nan</th>\n",
       "      <th>EMB_62_nan</th>\n",
       "      <th>EMB_63_nan</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.002611</td>\n",
       "      <td>-0.002001</td>\n",
       "      <td>-0.007244</td>\n",
       "      <td>-0.008264</td>\n",
       "      <td>-0.009245</td>\n",
       "      <td>0.004773</td>\n",
       "      <td>-0.004757</td>\n",
       "      <td>-0.009132</td>\n",
       "      <td>-0.003980</td>\n",
       "      <td>-0.003986</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016771</td>\n",
       "      <td>-0.032969</td>\n",
       "      <td>0.012735</td>\n",
       "      <td>-0.006551</td>\n",
       "      <td>-0.006155</td>\n",
       "      <td>0.003361</td>\n",
       "      <td>0.012964</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>0.004174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006203</td>\n",
       "      <td>-0.031904</td>\n",
       "      <td>-0.005630</td>\n",
       "      <td>-0.002246</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>-0.000785</td>\n",
       "      <td>-0.013895</td>\n",
       "      <td>-0.060086</td>\n",
       "      <td>0.012112</td>\n",
       "      <td>0.010161</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007051</td>\n",
       "      <td>0.014345</td>\n",
       "      <td>0.012054</td>\n",
       "      <td>0.025028</td>\n",
       "      <td>0.003834</td>\n",
       "      <td>0.009762</td>\n",
       "      <td>0.003318</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>-0.006457</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.013035</td>\n",
       "      <td>-0.031346</td>\n",
       "      <td>-0.007259</td>\n",
       "      <td>-0.027150</td>\n",
       "      <td>0.013176</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.008632</td>\n",
       "      <td>-0.018074</td>\n",
       "      <td>0.011783</td>\n",
       "      <td>0.013075</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019521</td>\n",
       "      <td>-0.003204</td>\n",
       "      <td>-0.009010</td>\n",
       "      <td>-0.009577</td>\n",
       "      <td>0.012087</td>\n",
       "      <td>0.012509</td>\n",
       "      <td>-0.007436</td>\n",
       "      <td>0.033228</td>\n",
       "      <td>0.020525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011535</td>\n",
       "      <td>0.002678</td>\n",
       "      <td>0.008933</td>\n",
       "      <td>-0.007592</td>\n",
       "      <td>0.013526</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>-0.004640</td>\n",
       "      <td>0.012302</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>-0.008446</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002434</td>\n",
       "      <td>-0.012074</td>\n",
       "      <td>0.027268</td>\n",
       "      <td>-0.002489</td>\n",
       "      <td>0.012693</td>\n",
       "      <td>-0.000898</td>\n",
       "      <td>-0.006660</td>\n",
       "      <td>0.020033</td>\n",
       "      <td>-0.011353</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000464</td>\n",
       "      <td>-0.001815</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>-0.005883</td>\n",
       "      <td>0.020563</td>\n",
       "      <td>0.008915</td>\n",
       "      <td>0.023891</td>\n",
       "      <td>-0.008433</td>\n",
       "      <td>0.009153</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>-0.009352</td>\n",
       "      <td>-0.004140</td>\n",
       "      <td>-0.017093</td>\n",
       "      <td>-0.012221</td>\n",
       "      <td>-0.006049</td>\n",
       "      <td>-0.004401</td>\n",
       "      <td>0.004302</td>\n",
       "      <td>-0.003082</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.017396</td>\n",
       "      <td>0.018430</td>\n",
       "      <td>-0.019600</td>\n",
       "      <td>-0.000973</td>\n",
       "      <td>0.005116</td>\n",
       "      <td>0.015510</td>\n",
       "      <td>-0.021879</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>-0.019197</td>\n",
       "      <td>0.022846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>-0.007688</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>-0.007874</td>\n",
       "      <td>-0.013986</td>\n",
       "      <td>0.018652</td>\n",
       "      <td>0.010788</td>\n",
       "      <td>-0.002692</td>\n",
       "      <td>-0.002896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.002049</td>\n",
       "      <td>-0.003535</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>-0.010233</td>\n",
       "      <td>-0.011990</td>\n",
       "      <td>0.010471</td>\n",
       "      <td>0.010511</td>\n",
       "      <td>0.006122</td>\n",
       "      <td>0.018677</td>\n",
       "      <td>-0.002852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003313</td>\n",
       "      <td>-0.002718</td>\n",
       "      <td>0.027768</td>\n",
       "      <td>0.012286</td>\n",
       "      <td>-0.015003</td>\n",
       "      <td>-0.010612</td>\n",
       "      <td>-0.012544</td>\n",
       "      <td>0.022089</td>\n",
       "      <td>-0.005592</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.003612</td>\n",
       "      <td>-0.013574</td>\n",
       "      <td>-0.000596</td>\n",
       "      <td>0.011884</td>\n",
       "      <td>-0.016282</td>\n",
       "      <td>0.018033</td>\n",
       "      <td>-0.010712</td>\n",
       "      <td>-0.010708</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>0.023245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>-0.001595</td>\n",
       "      <td>0.007095</td>\n",
       "      <td>-0.018613</td>\n",
       "      <td>0.012829</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>-0.007128</td>\n",
       "      <td>-0.000380</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002887</td>\n",
       "      <td>-0.014903</td>\n",
       "      <td>-0.013136</td>\n",
       "      <td>-0.017121</td>\n",
       "      <td>-0.001242</td>\n",
       "      <td>0.012092</td>\n",
       "      <td>0.026471</td>\n",
       "      <td>-0.005164</td>\n",
       "      <td>0.040155</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>-0.014485</td>\n",
       "      <td>-0.006645</td>\n",
       "      <td>-0.001124</td>\n",
       "      <td>0.026861</td>\n",
       "      <td>0.007188</td>\n",
       "      <td>0.003539</td>\n",
       "      <td>0.039540</td>\n",
       "      <td>0.024405</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.023049</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>-0.014058</td>\n",
       "      <td>-0.018598</td>\n",
       "      <td>0.010358</td>\n",
       "      <td>0.016791</td>\n",
       "      <td>-0.012068</td>\n",
       "      <td>0.025469</td>\n",
       "      <td>0.021957</td>\n",
       "      <td>-0.022532</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000346</td>\n",
       "      <td>-0.009741</td>\n",
       "      <td>0.027545</td>\n",
       "      <td>0.003370</td>\n",
       "      <td>0.023169</td>\n",
       "      <td>0.017635</td>\n",
       "      <td>-0.004659</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>-0.012603</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     EMB_00    EMB_01    EMB_02    EMB_03    EMB_04    EMB_05    EMB_06  \\\n",
       "0 -0.002611 -0.002001 -0.007244 -0.008264 -0.009245  0.004773 -0.004757   \n",
       "1  0.006203 -0.031904 -0.005630 -0.002246 -0.000162 -0.000785 -0.013895   \n",
       "2 -0.013035 -0.031346 -0.007259 -0.027150  0.013176  0.001905  0.008632   \n",
       "3  0.011535  0.002678  0.008933 -0.007592  0.013526  0.010309 -0.004640   \n",
       "4 -0.000464 -0.001815  0.007813 -0.005883  0.020563  0.008915  0.023891   \n",
       "5  0.017396  0.018430 -0.019600 -0.000973  0.005116  0.015510 -0.021879   \n",
       "6 -0.002049 -0.003535  0.003486 -0.010233 -0.011990  0.010471  0.010511   \n",
       "7 -0.003612 -0.013574 -0.000596  0.011884 -0.016282  0.018033 -0.010712   \n",
       "8  0.002887 -0.014903 -0.013136 -0.017121 -0.001242  0.012092  0.026471   \n",
       "9  0.023049  0.001317 -0.014058 -0.018598  0.010358  0.016791 -0.012068   \n",
       "\n",
       "     EMB_07    EMB_08    EMB_09  ...  EMB_55_nan  EMB_56_nan  EMB_57_nan  \\\n",
       "0 -0.009132 -0.003980 -0.003986  ...   -0.016771   -0.032969    0.012735   \n",
       "1 -0.060086  0.012112  0.010161  ...   -0.007051    0.014345    0.012054   \n",
       "2 -0.018074  0.011783  0.013075  ...   -0.019521   -0.003204   -0.009010   \n",
       "3  0.012302  0.000240 -0.008446  ...   -0.002434   -0.012074    0.027268   \n",
       "4 -0.008433  0.009153  0.001672  ...    0.004728   -0.009352   -0.004140   \n",
       "5  0.007576 -0.019197  0.022846  ...    0.002626   -0.007688    0.005242   \n",
       "6  0.006122  0.018677 -0.002852  ...    0.003313   -0.002718    0.027768   \n",
       "7 -0.010708  0.008789  0.023245  ...    0.002043   -0.001595    0.007095   \n",
       "8 -0.005164  0.040155  0.000823  ...    0.000451   -0.014485   -0.006645   \n",
       "9  0.025469  0.021957 -0.022532  ...   -0.000346   -0.009741    0.027545   \n",
       "\n",
       "   EMB_58_nan  EMB_59_nan  EMB_60_nan  EMB_61_nan  EMB_62_nan  EMB_63_nan  \\\n",
       "0   -0.006551   -0.006155    0.003361    0.012964    0.001979    0.004174   \n",
       "1    0.025028    0.003834    0.009762    0.003318    0.005872   -0.006457   \n",
       "2   -0.009577    0.012087    0.012509   -0.007436    0.033228    0.020525   \n",
       "3   -0.002489    0.012693   -0.000898   -0.006660    0.020033   -0.011353   \n",
       "4   -0.017093   -0.012221   -0.006049   -0.004401    0.004302   -0.003082   \n",
       "5   -0.007874   -0.013986    0.018652    0.010788   -0.002692   -0.002896   \n",
       "6    0.012286   -0.015003   -0.010612   -0.012544    0.022089   -0.005592   \n",
       "7   -0.018613    0.012829    0.010274    0.000282   -0.007128   -0.000380   \n",
       "8   -0.001124    0.026861    0.007188    0.003539    0.039540    0.024405   \n",
       "9    0.003370    0.023169    0.017635   -0.004659    0.005299   -0.012603   \n",
       "\n",
       "   prediction  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "5           0  \n",
       "6           0  \n",
       "7           0  \n",
       "8           0  \n",
       "9           0  \n",
       "\n",
       "[10 rows x 129 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# asset 실행\n",
    "inference_asset_structure=run(step, pipeline, asset_structure)\n",
    "\n",
    "# inference asset의 결과 dataframe은 inference_asset_structure.data['dataframe']으로 확인할 수 있습니다.  \n",
    "inference_asset_structure.data['dataframe'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93e1b561-2352-4474-ab09-c7ae583a7f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EMB_00', 'EMB_01', 'EMB_02', 'EMB_03', 'EMB_04', 'EMB_05', 'EMB_06',\n",
       "       'EMB_07', 'EMB_08', 'EMB_09',\n",
       "       ...\n",
       "       'EMB_55_nan', 'EMB_56_nan', 'EMB_57_nan', 'EMB_58_nan', 'EMB_59_nan',\n",
       "       'EMB_60_nan', 'EMB_61_nan', 'EMB_62_nan', 'EMB_63_nan', 'prediction'],\n",
       "      dtype='object', length=129)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_asset_structure.data['dataframe'].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e749a64d",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 3. Result asset \n",
    "##### Result asset의 args수정 및 확인\n",
    "- 필요한경우 Result_args의 항목을 ***asset_structure.args[argument명]=value입력*** 을 통해 변경할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17905521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result_save_name': None}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GCR asset 순서에 따라 step 순서를 입력합니다. (input(0) - preprocess(2) - inference(3) - result(4))\n",
    "step = 3\n",
    "asset_structure = copy.deepcopy(inference_asset_structure)\n",
    "asset_structure.args = alo.get_args(pipeline, step)\n",
    "\n",
    "# 아래 주석을 풀어 result asset argument를 원하는 값으로 수정합니다.\n",
    "# asset_structure.args['x_columns'] = ['']\n",
    "asset_structure.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74c2f5c",
   "metadata": {},
   "source": [
    "##### result asset 실행 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c899d49e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[2023-11-09 06:50:12,335][ASSET][INFO][inference_pipeline][result]: \n",
      "\n",
      "============================= ASSET START =============================\n",
      "- time (UTC)        : 2023-11-09 06:50:12\n",
      "- current step      : result\n",
      "- asset branch.     : release-1.2\n",
      "- alolib ver.       : 2.0\n",
      "- alo ver.          : release-2.0\n",
      "- load envs. keys   : dict_keys(['project_home', 'pipeline', 'step', 'num_step', 'artifacts', 'alo_version', 'asset_branch', 'interface_mode', 'load_data', 'load_config', 'save_data', 'save_config', 'log_file_path', 'prev_step'])\n",
      "- load args. keys   : dict_keys(['result_save_name'])\n",
      "- load config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess'])\n",
      "- load data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "Loading Embeddings\n",
      "\u001b[92m[2023-11-09 06:50:12,339][ASSET][INFO][inference_pipeline][result]: Successfully got model path for saving or loading your AI model: \n",
      " /home/jovyan/gcr/alo//.train_artifacts/models/result/\u001b[0m\n",
      "Merging data\n",
      "\u001b[92m[2023-11-09 06:50:12,367][ASSET][INFO][inference_pipeline][result]: Successfully got << output path >> for saving your data into csv or jpg file: \n",
      " /home/jovyan/gcr/alo//.inference_artifacts/output/result/ \n",
      " - [NOTE] The names of output file must be fixed as << output.csv, output.jpg >> \u001b[0m\n",
      "\u001b[92m[2023-11-09 06:50:12,372][ASSET][INFO][inference_pipeline][result]: Successfully got << output path >> for saving your data into csv or jpg file: \n",
      " /home/jovyan/gcr/alo//.inference_artifacts/output/result/ \n",
      " - [NOTE] The names of output file must be fixed as << output.csv, output.jpg >> \u001b[0m\n",
      "Check Result at /home/jovyan/gcr/alo//.inference_artifacts/output/result/inference_result.csv\n",
      "\u001b[94m[2023-11-09 06:50:12,373][ASSET][INFO][inference_pipeline][result]: \n",
      "\n",
      "============================= ASSET FINISH ===========================\n",
      "- time (UTC)        : 2023-11-09 06:50:12\n",
      "- current step      : result\n",
      "- save config. keys : dict_keys(['meta', 'data_source_type', 'time_format', 'time_column', 'x_columns', 'input_path', 'group_cnt', 'group_keys', 'y_column', 'input_asset_df_path', 'ignore_columns', 'columns_map', 'preprocess'])\n",
      "- save data keys    : dict_keys(['dataframe'])\n",
      "=======================================================================\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[94m[2023-11-09 06:50:12,375][PROCESS][INFO]: ==================== Finish pipeline: inference_pipeline / step: result\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>is_married</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gregory_Hull</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison_Peterson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Daniel_Davies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alison_Fox</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daniel_Moore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Barbara_Smith</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Paul_Terry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Christina_Salas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jose_Boyd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Zachary_Fowler</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  is_married  prediction\n",
       "0      Gregory_Hull         NaN           0\n",
       "1  Allison_Peterson         NaN           0\n",
       "2     Daniel_Davies         NaN           0\n",
       "3        Alison_Fox         NaN           0\n",
       "4      Daniel_Moore         NaN           0\n",
       "5     Barbara_Smith         NaN           0\n",
       "6        Paul_Terry         NaN           0\n",
       "7   Christina_Salas         NaN           0\n",
       "8         Jose_Boyd         NaN           0\n",
       "9    Zachary_Fowler         NaN           0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# asset 실행\n",
    "result_asset_structure=run(step, pipeline, asset_structure)\n",
    "\n",
    "# result asset의 결과 dataframe은 result_asset_structure.data['dataframe']으로 확인할 수 있습니다.\n",
    "result_asset_structure.data['dataframe'].head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcr",
   "language": "python",
   "name": "gcr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
